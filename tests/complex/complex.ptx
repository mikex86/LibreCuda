//
// Generated by LLVM NVPTX Back-End
//

.version 8.4
.target sm_89
.address_size 64

	// .globl	matmul_kernel
.extern .shared .align 16 .b8 global_smem[];

.visible .entry matmul_kernel(
	.param .u64 matmul_kernel_param_0,
	.param .u64 matmul_kernel_param_1,
	.param .u64 matmul_kernel_param_2,
	.param .u32 matmul_kernel_param_3,
	.param .u32 matmul_kernel_param_4,
	.param .u32 matmul_kernel_param_5,
	.param .u32 matmul_kernel_param_6,
	.param .u32 matmul_kernel_param_7,
	.param .u32 matmul_kernel_param_8
)
.maxntid 128, 1, 1
{
	.reg .pred 	%p<93>;
	.reg .b16 	%rs<577>;
	.reg .b32 	%r<2055>;
	.reg .f32 	%f<193>;
	.reg .b64 	%rd<137>;
	.loc	1 112 0
$L__func_begin0:
	.loc	1 112 0

	ld.param.u32 	%r331, [matmul_kernel_param_8];
	ld.param.u32 	%r330, [matmul_kernel_param_5];
	ld.param.u32 	%r329, [matmul_kernel_param_4];
	ld.param.u32 	%r328, [matmul_kernel_param_3];
	ld.param.u64 	%rd32, [matmul_kernel_param_2];
	ld.param.u64 	%rd31, [matmul_kernel_param_1];
	ld.param.u64 	%rd30, [matmul_kernel_param_0];
$L__tmp0:
	.loc	1 137 24
	// begin inline asm
	mov.u32 %r332, %ctaid.x;
	// end inline asm
$L__tmp1:
	.loc	2 40 22
	add.s32 	%r381, %r328, 127;
	.loc	2 40 28
	shr.s32 	%r382, %r381, 31;
	shr.u32 	%r383, %r382, 25;
	add.s32 	%r384, %r381, %r383;
	shr.s32 	%r385, %r384, 7;
$L__tmp2:
	.loc	2 40 22
	add.s32 	%r386, %r329, 127;
	.loc	2 40 28
	shr.s32 	%r387, %r386, 31;
	shr.u32 	%r388, %r387, 25;
	add.s32 	%r389, %r386, %r388;
	shr.s32 	%r390, %r389, 7;
$L__tmp3:
	.loc	1 140 38
	shl.b32 	%r392, %r390, 3;
	ld.param.u32 	%r393, [matmul_kernel_param_6];
	ld.param.u32 	%r394, [matmul_kernel_param_7];
	.loc	1 141 22
	div.s32 	%r395, %r332, %r392;
	.loc	1 142 29
	shl.b32 	%r396, %r395, 3;
	.loc	1 143 35
	sub.s32 	%r397, %r385, %r396;
	.loc	1 143 48
	min.s32 	%r398, %r397, 8;
	.loc	1 144 33
	rem.s32 	%r399, %r332, %r398;
	.loc	1 144 27
	add.s32 	%r400, %r396, %r399;
	mul.lo.s32 	%r401, %r395, %r392;
	sub.s32 	%r402, %r332, %r401;
	.loc	1 145 40
	div.s32 	%r403, %r402, %r398;
	.loc	1 154 23
	shl.b32 	%r1, %r400, 7;
	.loc	1 154 51
	mov.u32 	%r2, %tid.x;
	and.b32  	%r3, %r2, 31;
	shr.u32 	%r4, %r2, 5;
	shr.u32 	%r5, %r2, 2;
	bfe.u32 	%r404, %r2, 2, 5;
	or.b32  	%r405, %r404, 32;
	or.b32  	%r406, %r404, 64;
	or.b32  	%r407, %r404, 96;
	bfe.u32 	%r6, %r2, 4, 3;
	or.b32  	%r7, %r6, 8;
	or.b32  	%r8, %r6, 16;
	or.b32  	%r9, %r6, 24;
	shl.b32 	%r10, %r2, 3;
	and.b32  	%r11, %r10, 24;
	and.b32  	%r12, %r10, 120;
	.loc	1 154 38
	or.b32  	%r408, %r1, %r404;
	or.b32  	%r409, %r1, %r405;
	or.b32  	%r410, %r1, %r406;
	or.b32  	%r411, %r1, %r407;
	.loc	1 154 68
	rem.s32 	%r412, %r408, %r328;
	rem.s32 	%r413, %r409, %r328;
	rem.s32 	%r414, %r410, %r328;
	rem.s32 	%r415, %r411, %r328;
	.loc	1 155 23
	shl.b32 	%r416, %r403, 7;
	.loc	1 155 38
	or.b32  	%r13, %r416, %r12;
	.loc	1 155 68
	rem.s32 	%r417, %r13, %r329;
	.loc	1 157 53
	mad.lo.s32 	%r418, %r412, %r393, %r11;
	mad.lo.s32 	%r419, %r413, %r393, %r11;
	mad.lo.s32 	%r420, %r414, %r393, %r11;
	mad.lo.s32 	%r421, %r415, %r393, %r11;
	.loc	1 157 22
	mul.wide.s32 	%rd57, %r418, 2;
	add.s64 	%rd33, %rd30, %rd57;
	mul.wide.s32 	%rd58, %r419, 2;
	add.s64 	%rd34, %rd30, %rd58;
	mul.wide.s32 	%rd59, %r420, 2;
	add.s64 	%rd35, %rd30, %rd59;
	mul.wide.s32 	%rd60, %r421, 2;
	add.s64 	%rd36, %rd30, %rd60;
	.loc	1 158 40
	shl.b32 	%r422, %r394, 3;
	.loc	1 158 52
	mad.lo.s32 	%r423, %r6, %r394, %r417;
	add.s32 	%r424, %r423, %r422;
	add.s32 	%r425, %r424, %r422;
	add.s32 	%r426, %r425, %r422;
	.loc	1 158 22
	mul.wide.s32 	%rd61, %r423, 2;
	add.s64 	%rd37, %rd31, %rd61;
	mul.wide.s32 	%rd62, %r424, 2;
	add.s64 	%rd38, %rd31, %rd62;
	mul.wide.s32 	%rd63, %r425, 2;
	add.s64 	%rd39, %rd31, %rd63;
	mul.wide.s32 	%rd64, %r426, 2;
	add.s64 	%rd40, %rd31, %rd64;
$L__tmp4:
	.loc	2 40 22
	add.s32 	%r427, %r330, 31;
$L__tmp5:
	.loc	1 184 33
	shl.b32 	%r431, %r394, 5;
	.loc	1 173 22
	setp.gt.s32 	%p25, %r427, 31;
	.loc	1 176 54
	setp.lt.s32 	%p26, %r11, %r330;
	.loc	1 176 23
	shl.b32 	%r15, %r404, 5;
	or.b32  	%r16, %r15, %r11;
	shl.b32 	%r432, %r16, 1;
	mov.u32 	%r433, global_smem;
	add.s32 	%r333, %r433, %r432;
	shl.b32 	%r17, %r405, 5;
	or.b32  	%r18, %r17, %r11;
	shl.b32 	%r434, %r18, 1;
	add.s32 	%r335, %r433, %r434;
	shl.b32 	%r19, %r406, 5;
	or.b32  	%r20, %r19, %r11;
	shl.b32 	%r435, %r20, 1;
	add.s32 	%r337, %r433, %r435;
	shl.b32 	%r21, %r407, 5;
	or.b32  	%r22, %r21, %r11;
	shl.b32 	%r436, %r22, 1;
	add.s32 	%r339, %r433, %r436;
	selp.b32 	%r437, 16, 0, %p25;
	selp.b32 	%r336, %r437, 0, %p26;
	mov.pred 	%p24, -1;
	// begin inline asm
	@%p24 cp.async.cg.shared.global [ %r333 + 0 ], [ %rd33 + 0 ], 0x10, %r336;
	// end inline asm
	// begin inline asm
	@%p24 cp.async.cg.shared.global [ %r335 + 0 ], [ %rd34 + 0 ], 0x10, %r336;
	// end inline asm
	// begin inline asm
	@%p24 cp.async.cg.shared.global [ %r337 + 0 ], [ %rd35 + 0 ], 0x10, %r336;
	// end inline asm
	// begin inline asm
	@%p24 cp.async.cg.shared.global [ %r339 + 0 ], [ %rd36 + 0 ], 0x10, %r336;
	// end inline asm
	// begin inline asm
	cp.async.commit_group ;
	// end inline asm
	.loc	1 177 54
	setp.lt.s32 	%p27, %r6, %r330;
	setp.lt.s32 	%p28, %r7, %r330;
	setp.lt.s32 	%p29, %r8, %r330;
	setp.lt.s32 	%p30, %r9, %r330;
	.loc	1 177 23
	shl.b32 	%r23, %r6, 7;
	or.b32  	%r24, %r23, %r12;
	shl.b32 	%r438, %r24, 1;
	add.s32 	%r439, %r433, 24576;
	add.s32 	%r341, %r439, %r438;
	shl.b32 	%r25, %r7, 7;
	or.b32  	%r26, %r25, %r12;
	shl.b32 	%r440, %r26, 1;
	add.s32 	%r343, %r439, %r440;
	shl.b32 	%r27, %r8, 7;
	or.b32  	%r28, %r27, %r12;
	shl.b32 	%r441, %r28, 1;
	add.s32 	%r345, %r439, %r441;
	shl.b32 	%r29, %r9, 7;
	or.b32  	%r30, %r29, %r12;
	shl.b32 	%r442, %r30, 1;
	add.s32 	%r347, %r439, %r442;
	selp.b32 	%r342, %r437, 0, %p27;
	// begin inline asm
	@%p24 cp.async.cg.shared.global [ %r341 + 0 ], [ %rd37 + 0 ], 0x10, %r342;
	// end inline asm
	selp.b32 	%r344, %r437, 0, %p28;
	// begin inline asm
	@%p24 cp.async.cg.shared.global [ %r343 + 0 ], [ %rd38 + 0 ], 0x10, %r344;
	// end inline asm
	selp.b32 	%r346, %r437, 0, %p29;
	// begin inline asm
	@%p24 cp.async.cg.shared.global [ %r345 + 0 ], [ %rd39 + 0 ], 0x10, %r346;
	// end inline asm
	selp.b32 	%r348, %r437, 0, %p30;
	// begin inline asm
	@%p24 cp.async.cg.shared.global [ %r347 + 0 ], [ %rd40 + 0 ], 0x10, %r348;
	// end inline asm
	// begin inline asm
	cp.async.commit_group ;
	// end inline asm
	.loc	1 173 22
	setp.gt.s32 	%p31, %r427, 63;
	.loc	1 183 18
	add.s64 	%rd41, %rd33, 64;
	add.s64 	%rd42, %rd34, 64;
	add.s64 	%rd43, %rd35, 64;
	add.s64 	%rd44, %rd36, 64;
	.loc	1 184 18
	mul.wide.s32 	%rd65, %r431, 2;
	add.s64 	%rd45, %rd37, %rd65;
	add.s64 	%rd46, %rd38, %rd65;
	add.s64 	%rd47, %rd39, %rd65;
	add.s64 	%rd48, %rd40, %rd65;
	.loc	1 176 58
	add.s32 	%r443, %r330, -32;
	.loc	1 176 54
	setp.lt.s32 	%p32, %r11, %r443;
	.loc	1 176 23
	bar.sync 	0;
	add.s32 	%r444, %r433, 8192;
	add.s32 	%r349, %r444, %r432;
	add.s32 	%r351, %r444, %r434;
	add.s32 	%r353, %r444, %r435;
	add.s32 	%r355, %r444, %r436;
	selp.b32 	%r445, 16, 0, %p32;
	selp.b32 	%r352, %r445, 0, %p31;
	// begin inline asm
	@%p24 cp.async.cg.shared.global [ %r349 + 0 ], [ %rd41 + 0 ], 0x10, %r352;
	// end inline asm
	// begin inline asm
	@%p24 cp.async.cg.shared.global [ %r351 + 0 ], [ %rd42 + 0 ], 0x10, %r352;
	// end inline asm
	// begin inline asm
	@%p24 cp.async.cg.shared.global [ %r353 + 0 ], [ %rd43 + 0 ], 0x10, %r352;
	// end inline asm
	// begin inline asm
	@%p24 cp.async.cg.shared.global [ %r355 + 0 ], [ %rd44 + 0 ], 0x10, %r352;
	// end inline asm
	// begin inline asm
	cp.async.commit_group ;
	// end inline asm
	.loc	1 177 54
	setp.lt.s32 	%p33, %r6, %r443;
	setp.lt.s32 	%p34, %r7, %r443;
	setp.lt.s32 	%p35, %r8, %r443;
	setp.lt.s32 	%p36, %r9, %r443;
	.loc	1 177 23
	add.s32 	%r446, %r433, 32768;
	add.s32 	%r357, %r446, %r438;
	add.s32 	%r359, %r446, %r440;
	add.s32 	%r361, %r446, %r441;
	add.s32 	%r363, %r446, %r442;
	selp.b32 	%r447, 16, 0, %p33;
	selp.b32 	%r358, %r447, 0, %p31;
	// begin inline asm
	@%p24 cp.async.cg.shared.global [ %r357 + 0 ], [ %rd45 + 0 ], 0x10, %r358;
	// end inline asm
	selp.b32 	%r448, 16, 0, %p34;
	selp.b32 	%r360, %r448, 0, %p31;
	// begin inline asm
	@%p24 cp.async.cg.shared.global [ %r359 + 0 ], [ %rd46 + 0 ], 0x10, %r360;
	// end inline asm
	selp.b32 	%r449, 16, 0, %p35;
	selp.b32 	%r362, %r449, 0, %p31;
	// begin inline asm
	@%p24 cp.async.cg.shared.global [ %r361 + 0 ], [ %rd47 + 0 ], 0x10, %r362;
	// end inline asm
	selp.b32 	%r450, 16, 0, %p36;
	selp.b32 	%r364, %r450, 0, %p31;
	// begin inline asm
	@%p24 cp.async.cg.shared.global [ %r363 + 0 ], [ %rd48 + 0 ], 0x10, %r364;
	// end inline asm
	// begin inline asm
	cp.async.commit_group ;
	// end inline asm
	.loc	1 173 22
	setp.gt.s32 	%p37, %r427, 95;
	.loc	1 183 18
	add.s64 	%rd49, %rd33, 128;
	add.s64 	%rd50, %rd34, 128;
	add.s64 	%rd51, %rd35, 128;
	add.s64 	%rd52, %rd36, 128;
	.loc	1 184 18
	add.s64 	%rd53, %rd45, %rd65;
	add.s64 	%rd54, %rd46, %rd65;
	add.s64 	%rd55, %rd47, %rd65;
	add.s64 	%rd56, %rd48, %rd65;
	.loc	1 176 58
	add.s32 	%r451, %r330, -64;
	.loc	1 176 54
	setp.lt.s32 	%p38, %r11, %r451;
	.loc	1 176 23
	bar.sync 	0;
	add.s32 	%r452, %r433, 16384;
	add.s32 	%r365, %r452, %r432;
	add.s32 	%r367, %r452, %r434;
	add.s32 	%r369, %r452, %r435;
	add.s32 	%r371, %r452, %r436;
	selp.b32 	%r453, 16, 0, %p38;
	selp.b32 	%r368, %r453, 0, %p37;
	// begin inline asm
	@%p24 cp.async.cg.shared.global [ %r365 + 0 ], [ %rd49 + 0 ], 0x10, %r368;
	// end inline asm
	// begin inline asm
	@%p24 cp.async.cg.shared.global [ %r367 + 0 ], [ %rd50 + 0 ], 0x10, %r368;
	// end inline asm
	// begin inline asm
	@%p24 cp.async.cg.shared.global [ %r369 + 0 ], [ %rd51 + 0 ], 0x10, %r368;
	// end inline asm
	// begin inline asm
	@%p24 cp.async.cg.shared.global [ %r371 + 0 ], [ %rd52 + 0 ], 0x10, %r368;
	// end inline asm
	// begin inline asm
	cp.async.commit_group ;
	// end inline asm
	.loc	1 177 54
	setp.lt.s32 	%p39, %r6, %r451;
	setp.lt.s32 	%p40, %r7, %r451;
	setp.lt.s32 	%p41, %r8, %r451;
	setp.lt.s32 	%p42, %r9, %r451;
	.loc	1 177 23
	add.s32 	%r454, %r433, 40960;
	add.s32 	%r373, %r454, %r438;
	add.s32 	%r375, %r454, %r440;
	add.s32 	%r377, %r454, %r441;
	add.s32 	%r379, %r454, %r442;
	selp.b32 	%r455, 16, 0, %p39;
	selp.b32 	%r374, %r455, 0, %p37;
	// begin inline asm
	@%p24 cp.async.cg.shared.global [ %r373 + 0 ], [ %rd53 + 0 ], 0x10, %r374;
	// end inline asm
	selp.b32 	%r456, 16, 0, %p40;
	selp.b32 	%r376, %r456, 0, %p37;
	// begin inline asm
	@%p24 cp.async.cg.shared.global [ %r375 + 0 ], [ %rd54 + 0 ], 0x10, %r376;
	// end inline asm
	selp.b32 	%r457, 16, 0, %p41;
	selp.b32 	%r378, %r457, 0, %p37;
	// begin inline asm
	@%p24 cp.async.cg.shared.global [ %r377 + 0 ], [ %rd55 + 0 ], 0x10, %r378;
	// end inline asm
	selp.b32 	%r458, 16, 0, %p42;
	selp.b32 	%r380, %r458, 0, %p37;
	// begin inline asm
	@%p24 cp.async.cg.shared.global [ %r379 + 0 ], [ %rd56 + 0 ], 0x10, %r380;
	// end inline asm
	// begin inline asm
	cp.async.commit_group ;
	// end inline asm
	.loc	1 176 23
	// begin inline asm
	cp.async.wait_group 0x4;
	// end inline asm
	bar.sync 	0;
	.loc	1 173 22
	@%p25 bra 	$L__BB0_2;
	bra.uni 	$L__BB0_1;
$L__BB0_2:
	.loc	1 0 22
	cvt.s64.s32 	%rd1, %r418;
	cvt.s64.s32 	%rd2, %r419;
	cvt.s64.s32 	%rd3, %r420;
	cvt.s64.s32 	%rd4, %r421;
	cvt.s64.s32 	%rd5, %r423;
	cvt.s64.s32 	%rd6, %r424;
	cvt.s64.s32 	%rd7, %r425;
	cvt.s64.s32 	%rd8, %r426;
	shr.s32 	%r428, %r427, 31;
	shr.u32 	%r429, %r428, 27;
	add.s32 	%r430, %r427, %r429;
	shr.s32 	%r14, %r430, 5;
	cvt.s64.s32 	%rd9, %r431;
	add.s32 	%r32, %r14, -3;
	xor.b32  	%r465, %r10, %r2;
	and.b32  	%r466, %r465, 24;
	or.b32  	%r467, %r15, %r466;
	shl.b32 	%r468, %r467, 1;
	add.s32 	%r469, %r433, 49152;
	add.s32 	%r33, %r469, %r468;
	or.b32  	%r470, %r17, %r466;
	shl.b32 	%r471, %r470, 1;
	add.s32 	%r34, %r469, %r471;
	or.b32  	%r472, %r19, %r466;
	shl.b32 	%r473, %r472, 1;
	add.s32 	%r35, %r469, %r473;
	or.b32  	%r474, %r21, %r466;
	shl.b32 	%r475, %r474, 1;
	add.s32 	%r36, %r469, %r475;
	shr.u32 	%r476, %r2, 1;
	and.b32  	%r477, %r476, 56;
	xor.b32  	%r478, %r477, %r12;
	or.b32  	%r479, %r478, %r23;
	shl.b32 	%r480, %r479, 1;
	add.s32 	%r481, %r433, 57344;
	add.s32 	%r37, %r481, %r480;
	or.b32  	%r482, %r25, %r478;
	shl.b32 	%r483, %r482, 1;
	add.s32 	%r38, %r481, %r483;
	or.b32  	%r484, %r27, %r478;
	shl.b32 	%r485, %r484, 1;
	add.s32 	%r39, %r481, %r485;
	or.b32  	%r486, %r29, %r478;
	shl.b32 	%r487, %r486, 1;
	add.s32 	%r40, %r481, %r487;
	and.b32  	%r488, %r2, 7;
	bfe.u32 	%r489, %r2, 3, 1;
	shr.u32 	%r1990, %r3, 4;
	and.b32  	%r490, %r4, 2;
	or.b32  	%r491, %r490, %r489;
	bfe.u32 	%r492, %r2, 1, 2;
	xor.b32  	%r493, %r1990, %r492;
	shl.b32 	%r494, %r493, 4;
	shl.b32 	%r495, %r491, 9;
	shl.b32 	%r496, %r488, 6;
	or.b32  	%r497, %r495, %r496;
	or.b32  	%r498, %r494, %r497;
	add.s32 	%r595, %r469, %r498;
	or.b32  	%r499, %r1990, 2;
	xor.b32  	%r500, %r499, %r492;
	shl.b32 	%r501, %r500, 4;
	or.b32  	%r502, %r501, %r497;
	add.s32 	%r600, %r469, %r502;
	add.s32 	%r605, %r595, 2048;
	add.s32 	%r610, %r600, 2048;
	add.s32 	%r615, %r595, 4096;
	add.s32 	%r620, %r600, 4096;
	add.s32 	%r625, %r595, 6144;
	add.s32 	%r630, %r600, 6144;
	and.b32  	%r503, %r4, 1;
	shl.b32 	%r504, %r1990, 1;
	or.b32  	%r505, %r504, %r503;
	xor.b32  	%r506, %r505, %r488;
	shl.b32 	%r507, %r2, 7;
	and.b32  	%r508, %r507, 1920;
	shl.b32 	%r509, %r506, 4;
	shl.b32 	%r510, %r508, 1;
	or.b32  	%r511, %r509, %r510;
	add.s32 	%r635, %r481, %r511;
	add.s32 	%r640, %r635, 4096;
	or.b32  	%r512, %r505, 4;
	xor.b32  	%r513, %r512, %r488;
	shl.b32 	%r514, %r513, 3;
	add.s32 	%r515, %r514, %r508;
	shl.b32 	%r516, %r515, 1;
	add.s32 	%r645, %r481, %r516;
	add.s32 	%r650, %r645, 4096;
	or.b32  	%r517, %r505, 8;
	xor.b32  	%r518, %r517, %r488;
	shl.b32 	%r519, %r518, 3;
	add.s32 	%r520, %r519, %r508;
	shl.b32 	%r521, %r520, 1;
	add.s32 	%r655, %r481, %r521;
	add.s32 	%r660, %r655, 4096;
	or.b32  	%r522, %r505, 12;
	xor.b32  	%r523, %r522, %r488;
	shl.b32 	%r524, %r523, 3;
	add.s32 	%r525, %r524, %r508;
	shl.b32 	%r526, %r525, 1;
	add.s32 	%r665, %r481, %r526;
	add.s32 	%r670, %r665, 4096;
	add.s32 	%r1920, %r330, -96;
	.loc	1 173 22
	shl.b64 	%rd10, %rd8, 1;
	mul.lo.s64 	%rd66, %rd9, 6;
	add.s64 	%rd136, %rd31, %rd66;
	shl.b64 	%rd12, %rd9, 1;
	shl.b64 	%rd13, %rd7, 1;
	shl.b64 	%rd14, %rd6, 1;
	shl.b64 	%rd15, %rd5, 1;
	shl.b64 	%rd67, %rd4, 1;
	add.s64 	%rd68, %rd67, %rd30;
	add.s64 	%rd135, %rd68, 192;
	shl.b64 	%rd69, %rd3, 1;
	add.s64 	%rd70, %rd69, %rd30;
	add.s64 	%rd134, %rd70, 192;
	shl.b64 	%rd71, %rd2, 1;
	add.s64 	%rd72, %rd71, %rd30;
	add.s64 	%rd133, %rd72, 192;
	shl.b64 	%rd73, %rd1, 1;
	add.s64 	%rd74, %rd73, %rd30;
	add.s64 	%rd132, %rd74, 192;
	mov.b32 	%r1926, 0;
	mov.b32 	%r1924, 2;
	mov.b32 	%r1923, 0;
	mov.u32 	%r1921, %r439;
	mov.u32 	%r1922, %r433;
	mov.u32 	%r1925, %r1923;
	mov.u32 	%r1927, %r1926;
	mov.u32 	%r1928, %r1926;
	mov.u32 	%r1929, %r1926;
	mov.u32 	%r1930, %r1926;
	mov.u32 	%r1931, %r1926;
	mov.u32 	%r1932, %r1926;
	mov.u32 	%r1933, %r1926;
	mov.u32 	%r1934, %r1926;
	mov.u32 	%r1935, %r1926;
	mov.u32 	%r1936, %r1926;
	mov.u32 	%r1937, %r1926;
	mov.u32 	%r1938, %r1926;
	mov.u32 	%r1939, %r1926;
	mov.u32 	%r1940, %r1926;
	mov.u32 	%r1941, %r1926;
	mov.u32 	%r1942, %r1926;
	mov.u32 	%r1943, %r1926;
	mov.u32 	%r1944, %r1926;
	mov.u32 	%r1945, %r1926;
	mov.u32 	%r1946, %r1926;
	mov.u32 	%r1947, %r1926;
	mov.u32 	%r1948, %r1926;
	mov.u32 	%r1949, %r1926;
	mov.u32 	%r1950, %r1926;
	mov.u32 	%r1951, %r1926;
	mov.u32 	%r1952, %r1926;
	mov.u32 	%r1953, %r1926;
	mov.u32 	%r1954, %r1926;
	mov.u32 	%r1955, %r1926;
	mov.u32 	%r1956, %r1926;
	mov.u32 	%r1957, %r1926;
	mov.u32 	%r1958, %r1926;
	mov.u32 	%r1959, %r1926;
	mov.u32 	%r1960, %r1926;
	mov.u32 	%r1961, %r1926;
	mov.u32 	%r1962, %r1926;
	mov.u32 	%r1963, %r1926;
	mov.u32 	%r1964, %r1926;
	mov.u32 	%r1965, %r1926;
	mov.u32 	%r1966, %r1926;
	mov.u32 	%r1967, %r1926;
	mov.u32 	%r1968, %r1926;
	mov.u32 	%r1969, %r1926;
	mov.u32 	%r1970, %r1926;
	mov.u32 	%r1971, %r1926;
	mov.u32 	%r1972, %r1926;
	mov.u32 	%r1973, %r1926;
	mov.u32 	%r1974, %r1926;
	mov.u32 	%r1975, %r1926;
	mov.u32 	%r1976, %r1926;
	mov.u32 	%r1977, %r1926;
	mov.u32 	%r1978, %r1926;
	mov.u32 	%r1979, %r1926;
	mov.u32 	%r1980, %r1926;
	mov.u32 	%r1981, %r1926;
	mov.u32 	%r1982, %r1926;
	mov.u32 	%r1983, %r1926;
	mov.u32 	%r1984, %r1926;
	mov.u32 	%r1985, %r1926;
	mov.u32 	%r1986, %r1926;
	mov.u32 	%r1987, %r1926;
	mov.u32 	%r1988, %r1926;
	mov.u32 	%r1989, %r1926;
$L__BB0_3:
	setp.lt.s32 	%p51, %r1925, %r32;
	.loc	1 176 23
	add.s32 	%r1328, %r1922, %r432;
	ld.shared.v4.b32 	{%r1329, %r1330, %r1331, %r1332}, [%r1328];
	mov.b32 	{%rs65, %rs66}, %r1332;
	mov.b32 	{%rs67, %rs68}, %r1331;
	mov.b32 	{%rs69, %rs70}, %r1330;
	mov.b32 	{%rs71, %rs72}, %r1329;
	add.s32 	%r1334, %r1922, %r434;
	ld.shared.v4.b32 	{%r1335, %r1336, %r1337, %r1338}, [%r1334];
	mov.b32 	{%rs73, %rs74}, %r1338;
	mov.b32 	{%rs75, %rs76}, %r1337;
	mov.b32 	{%rs77, %rs78}, %r1336;
	mov.b32 	{%rs79, %rs80}, %r1335;
	add.s32 	%r1340, %r1922, %r435;
	ld.shared.v4.b32 	{%r1341, %r1342, %r1343, %r1344}, [%r1340];
	mov.b32 	{%rs81, %rs82}, %r1344;
	mov.b32 	{%rs83, %rs84}, %r1343;
	mov.b32 	{%rs85, %rs86}, %r1342;
	mov.b32 	{%rs87, %rs88}, %r1341;
	add.s32 	%r1346, %r1922, %r436;
	ld.shared.v4.b32 	{%r1347, %r1348, %r1349, %r1350}, [%r1346];
	mov.b32 	{%rs89, %rs90}, %r1350;
	mov.b32 	{%rs91, %rs92}, %r1349;
	mov.b32 	{%rs93, %rs94}, %r1348;
	mov.b32 	{%rs95, %rs96}, %r1347;
	.loc	1 177 23
	add.s32 	%r1352, %r1921, %r438;
	ld.shared.v4.b32 	{%r1353, %r1354, %r1355, %r1356}, [%r1352];
	mov.b32 	{%rs97, %rs98}, %r1356;
	mov.b32 	{%rs99, %rs100}, %r1355;
	mov.b32 	{%rs101, %rs102}, %r1354;
	mov.b32 	{%rs103, %rs104}, %r1353;
	add.s32 	%r1358, %r1921, %r440;
	ld.shared.v4.b32 	{%r1359, %r1360, %r1361, %r1362}, [%r1358];
	mov.b32 	{%rs105, %rs106}, %r1362;
	mov.b32 	{%rs107, %rs108}, %r1361;
	mov.b32 	{%rs109, %rs110}, %r1360;
	mov.b32 	{%rs111, %rs112}, %r1359;
	add.s32 	%r1364, %r1921, %r441;
	ld.shared.v4.b32 	{%r1365, %r1366, %r1367, %r1368}, [%r1364];
	mov.b32 	{%rs113, %rs114}, %r1368;
	mov.b32 	{%rs115, %rs116}, %r1367;
	mov.b32 	{%rs117, %rs118}, %r1366;
	mov.b32 	{%rs119, %rs120}, %r1365;
	add.s32 	%r1370, %r1921, %r442;
	ld.shared.v4.b32 	{%r1371, %r1372, %r1373, %r1374}, [%r1370];
	mov.b32 	{%rs121, %rs122}, %r1374;
	mov.b32 	{%rs123, %rs124}, %r1373;
	mov.b32 	{%rs125, %rs126}, %r1372;
	mov.b32 	{%rs127, %rs128}, %r1371;
	.loc	1 178 20
	// begin inline asm
	cvt.f32.bf16 %r527, %rs71;
	// end inline asm
	mov.b32 	%f1, %r527;
	// begin inline asm
	cvt.f32.bf16 %r528, %rs72;
	// end inline asm
	mov.b32 	%f2, %r528;
	// begin inline asm
	cvt.f32.bf16 %r529, %rs69;
	// end inline asm
	mov.b32 	%f3, %r529;
	// begin inline asm
	cvt.f32.bf16 %r530, %rs70;
	// end inline asm
	mov.b32 	%f4, %r530;
	// begin inline asm
	cvt.f32.bf16 %r531, %rs67;
	// end inline asm
	mov.b32 	%f5, %r531;
	// begin inline asm
	cvt.f32.bf16 %r532, %rs68;
	// end inline asm
	mov.b32 	%f6, %r532;
	// begin inline asm
	cvt.f32.bf16 %r533, %rs65;
	// end inline asm
	mov.b32 	%f7, %r533;
	// begin inline asm
	cvt.f32.bf16 %r534, %rs66;
	// end inline asm
	mov.b32 	%f8, %r534;
	// begin inline asm
	cvt.f32.bf16 %r535, %rs79;
	// end inline asm
	mov.b32 	%f9, %r535;
	// begin inline asm
	cvt.f32.bf16 %r536, %rs80;
	// end inline asm
	mov.b32 	%f10, %r536;
	// begin inline asm
	cvt.f32.bf16 %r537, %rs77;
	// end inline asm
	mov.b32 	%f11, %r537;
	// begin inline asm
	cvt.f32.bf16 %r538, %rs78;
	// end inline asm
	mov.b32 	%f12, %r538;
	// begin inline asm
	cvt.f32.bf16 %r539, %rs75;
	// end inline asm
	mov.b32 	%f13, %r539;
	// begin inline asm
	cvt.f32.bf16 %r540, %rs76;
	// end inline asm
	mov.b32 	%f14, %r540;
	// begin inline asm
	cvt.f32.bf16 %r541, %rs73;
	// end inline asm
	mov.b32 	%f15, %r541;
	// begin inline asm
	cvt.f32.bf16 %r542, %rs74;
	// end inline asm
	mov.b32 	%f16, %r542;
	// begin inline asm
	cvt.f32.bf16 %r543, %rs87;
	// end inline asm
	mov.b32 	%f17, %r543;
	// begin inline asm
	cvt.f32.bf16 %r544, %rs88;
	// end inline asm
	mov.b32 	%f18, %r544;
	// begin inline asm
	cvt.f32.bf16 %r545, %rs85;
	// end inline asm
	mov.b32 	%f19, %r545;
	// begin inline asm
	cvt.f32.bf16 %r546, %rs86;
	// end inline asm
	mov.b32 	%f20, %r546;
	// begin inline asm
	cvt.f32.bf16 %r547, %rs83;
	// end inline asm
	mov.b32 	%f21, %r547;
	// begin inline asm
	cvt.f32.bf16 %r548, %rs84;
	// end inline asm
	mov.b32 	%f22, %r548;
	// begin inline asm
	cvt.f32.bf16 %r549, %rs81;
	// end inline asm
	mov.b32 	%f23, %r549;
	// begin inline asm
	cvt.f32.bf16 %r550, %rs82;
	// end inline asm
	mov.b32 	%f24, %r550;
	// begin inline asm
	cvt.f32.bf16 %r551, %rs95;
	// end inline asm
	mov.b32 	%f25, %r551;
	// begin inline asm
	cvt.f32.bf16 %r552, %rs96;
	// end inline asm
	mov.b32 	%f26, %r552;
	// begin inline asm
	cvt.f32.bf16 %r553, %rs93;
	// end inline asm
	mov.b32 	%f27, %r553;
	// begin inline asm
	cvt.f32.bf16 %r554, %rs94;
	// end inline asm
	mov.b32 	%f28, %r554;
	// begin inline asm
	cvt.f32.bf16 %r555, %rs91;
	// end inline asm
	mov.b32 	%f29, %r555;
	// begin inline asm
	cvt.f32.bf16 %r556, %rs92;
	// end inline asm
	mov.b32 	%f30, %r556;
	// begin inline asm
	cvt.f32.bf16 %r557, %rs89;
	// end inline asm
	mov.b32 	%f31, %r557;
	// begin inline asm
	cvt.f32.bf16 %r558, %rs90;
	// end inline asm
	mov.b32 	%f32, %r558;
	cvt.rn.f16.f32 	%rs129, %f8;
	cvt.rn.f16.f32 	%rs130, %f7;
	mov.b32 	%r1375, {%rs130, %rs129};
	cvt.rn.f16.f32 	%rs131, %f6;
	cvt.rn.f16.f32 	%rs132, %f5;
	mov.b32 	%r1376, {%rs132, %rs131};
	cvt.rn.f16.f32 	%rs133, %f4;
	cvt.rn.f16.f32 	%rs134, %f3;
	mov.b32 	%r1377, {%rs134, %rs133};
	cvt.rn.f16.f32 	%rs135, %f2;
	cvt.rn.f16.f32 	%rs136, %f1;
	mov.b32 	%r1378, {%rs136, %rs135};
	cvt.rn.f16.f32 	%rs137, %f16;
	cvt.rn.f16.f32 	%rs138, %f15;
	mov.b32 	%r1379, {%rs138, %rs137};
	cvt.rn.f16.f32 	%rs139, %f14;
	cvt.rn.f16.f32 	%rs140, %f13;
	mov.b32 	%r1380, {%rs140, %rs139};
	cvt.rn.f16.f32 	%rs141, %f12;
	cvt.rn.f16.f32 	%rs142, %f11;
	mov.b32 	%r1381, {%rs142, %rs141};
	cvt.rn.f16.f32 	%rs143, %f10;
	cvt.rn.f16.f32 	%rs144, %f9;
	mov.b32 	%r1382, {%rs144, %rs143};
	cvt.rn.f16.f32 	%rs145, %f24;
	cvt.rn.f16.f32 	%rs146, %f23;
	mov.b32 	%r1383, {%rs146, %rs145};
	cvt.rn.f16.f32 	%rs147, %f22;
	cvt.rn.f16.f32 	%rs148, %f21;
	mov.b32 	%r1384, {%rs148, %rs147};
	cvt.rn.f16.f32 	%rs149, %f20;
	cvt.rn.f16.f32 	%rs150, %f19;
	mov.b32 	%r1385, {%rs150, %rs149};
	cvt.rn.f16.f32 	%rs151, %f18;
	cvt.rn.f16.f32 	%rs152, %f17;
	mov.b32 	%r1386, {%rs152, %rs151};
	cvt.rn.f16.f32 	%rs153, %f32;
	cvt.rn.f16.f32 	%rs154, %f31;
	mov.b32 	%r1387, {%rs154, %rs153};
	cvt.rn.f16.f32 	%rs155, %f30;
	cvt.rn.f16.f32 	%rs156, %f29;
	mov.b32 	%r1388, {%rs156, %rs155};
	cvt.rn.f16.f32 	%rs157, %f28;
	cvt.rn.f16.f32 	%rs158, %f27;
	mov.b32 	%r1389, {%rs158, %rs157};
	cvt.rn.f16.f32 	%rs159, %f26;
	cvt.rn.f16.f32 	%rs160, %f25;
	mov.b32 	%r1390, {%rs160, %rs159};
	.loc	1 178 34
	st.shared.v4.b32 	[%r33], {%r1378, %r1377, %r1376, %r1375};
	st.shared.v4.b32 	[%r34], {%r1382, %r1381, %r1380, %r1379};
	st.shared.v4.b32 	[%r35], {%r1386, %r1385, %r1384, %r1383};
	st.shared.v4.b32 	[%r36], {%r1390, %r1389, %r1388, %r1387};
	.loc	1 179 20
	// begin inline asm
	cvt.f32.bf16 %r559, %rs103;
	// end inline asm
	mov.b32 	%f33, %r559;
	// begin inline asm
	cvt.f32.bf16 %r560, %rs104;
	// end inline asm
	mov.b32 	%f34, %r560;
	// begin inline asm
	cvt.f32.bf16 %r561, %rs101;
	// end inline asm
	mov.b32 	%f35, %r561;
	// begin inline asm
	cvt.f32.bf16 %r562, %rs102;
	// end inline asm
	mov.b32 	%f36, %r562;
	// begin inline asm
	cvt.f32.bf16 %r563, %rs99;
	// end inline asm
	mov.b32 	%f37, %r563;
	// begin inline asm
	cvt.f32.bf16 %r564, %rs100;
	// end inline asm
	mov.b32 	%f38, %r564;
	// begin inline asm
	cvt.f32.bf16 %r565, %rs97;
	// end inline asm
	mov.b32 	%f39, %r565;
	// begin inline asm
	cvt.f32.bf16 %r566, %rs98;
	// end inline asm
	mov.b32 	%f40, %r566;
	// begin inline asm
	cvt.f32.bf16 %r567, %rs111;
	// end inline asm
	mov.b32 	%f41, %r567;
	// begin inline asm
	cvt.f32.bf16 %r568, %rs112;
	// end inline asm
	mov.b32 	%f42, %r568;
	// begin inline asm
	cvt.f32.bf16 %r569, %rs109;
	// end inline asm
	mov.b32 	%f43, %r569;
	// begin inline asm
	cvt.f32.bf16 %r570, %rs110;
	// end inline asm
	mov.b32 	%f44, %r570;
	// begin inline asm
	cvt.f32.bf16 %r571, %rs107;
	// end inline asm
	mov.b32 	%f45, %r571;
	// begin inline asm
	cvt.f32.bf16 %r572, %rs108;
	// end inline asm
	mov.b32 	%f46, %r572;
	// begin inline asm
	cvt.f32.bf16 %r573, %rs105;
	// end inline asm
	mov.b32 	%f47, %r573;
	// begin inline asm
	cvt.f32.bf16 %r574, %rs106;
	// end inline asm
	mov.b32 	%f48, %r574;
	// begin inline asm
	cvt.f32.bf16 %r575, %rs119;
	// end inline asm
	mov.b32 	%f49, %r575;
	// begin inline asm
	cvt.f32.bf16 %r576, %rs120;
	// end inline asm
	mov.b32 	%f50, %r576;
	// begin inline asm
	cvt.f32.bf16 %r577, %rs117;
	// end inline asm
	mov.b32 	%f51, %r577;
	// begin inline asm
	cvt.f32.bf16 %r578, %rs118;
	// end inline asm
	mov.b32 	%f52, %r578;
	// begin inline asm
	cvt.f32.bf16 %r579, %rs115;
	// end inline asm
	mov.b32 	%f53, %r579;
	// begin inline asm
	cvt.f32.bf16 %r580, %rs116;
	// end inline asm
	mov.b32 	%f54, %r580;
	// begin inline asm
	cvt.f32.bf16 %r581, %rs113;
	// end inline asm
	mov.b32 	%f55, %r581;
	// begin inline asm
	cvt.f32.bf16 %r582, %rs114;
	// end inline asm
	mov.b32 	%f56, %r582;
	// begin inline asm
	cvt.f32.bf16 %r583, %rs127;
	// end inline asm
	mov.b32 	%f57, %r583;
	// begin inline asm
	cvt.f32.bf16 %r584, %rs128;
	// end inline asm
	mov.b32 	%f58, %r584;
	// begin inline asm
	cvt.f32.bf16 %r585, %rs125;
	// end inline asm
	mov.b32 	%f59, %r585;
	// begin inline asm
	cvt.f32.bf16 %r586, %rs126;
	// end inline asm
	mov.b32 	%f60, %r586;
	// begin inline asm
	cvt.f32.bf16 %r587, %rs123;
	// end inline asm
	mov.b32 	%f61, %r587;
	// begin inline asm
	cvt.f32.bf16 %r588, %rs124;
	// end inline asm
	mov.b32 	%f62, %r588;
	// begin inline asm
	cvt.f32.bf16 %r589, %rs121;
	// end inline asm
	mov.b32 	%f63, %r589;
	// begin inline asm
	cvt.f32.bf16 %r590, %rs122;
	// end inline asm
	mov.b32 	%f64, %r590;
	cvt.rn.f16.f32 	%rs161, %f40;
	cvt.rn.f16.f32 	%rs162, %f39;
	mov.b32 	%r1391, {%rs162, %rs161};
	cvt.rn.f16.f32 	%rs163, %f38;
	cvt.rn.f16.f32 	%rs164, %f37;
	mov.b32 	%r1392, {%rs164, %rs163};
	cvt.rn.f16.f32 	%rs165, %f36;
	cvt.rn.f16.f32 	%rs166, %f35;
	mov.b32 	%r1393, {%rs166, %rs165};
	cvt.rn.f16.f32 	%rs167, %f34;
	cvt.rn.f16.f32 	%rs168, %f33;
	mov.b32 	%r1394, {%rs168, %rs167};
	cvt.rn.f16.f32 	%rs169, %f48;
	cvt.rn.f16.f32 	%rs170, %f47;
	mov.b32 	%r1395, {%rs170, %rs169};
	cvt.rn.f16.f32 	%rs171, %f46;
	cvt.rn.f16.f32 	%rs172, %f45;
	mov.b32 	%r1396, {%rs172, %rs171};
	cvt.rn.f16.f32 	%rs173, %f44;
	cvt.rn.f16.f32 	%rs174, %f43;
	mov.b32 	%r1397, {%rs174, %rs173};
	cvt.rn.f16.f32 	%rs175, %f42;
	cvt.rn.f16.f32 	%rs176, %f41;
	mov.b32 	%r1398, {%rs176, %rs175};
	cvt.rn.f16.f32 	%rs177, %f56;
	cvt.rn.f16.f32 	%rs178, %f55;
	mov.b32 	%r1399, {%rs178, %rs177};
	cvt.rn.f16.f32 	%rs179, %f54;
	cvt.rn.f16.f32 	%rs180, %f53;
	mov.b32 	%r1400, {%rs180, %rs179};
	cvt.rn.f16.f32 	%rs181, %f52;
	cvt.rn.f16.f32 	%rs182, %f51;
	mov.b32 	%r1401, {%rs182, %rs181};
	cvt.rn.f16.f32 	%rs183, %f50;
	cvt.rn.f16.f32 	%rs184, %f49;
	mov.b32 	%r1402, {%rs184, %rs183};
	cvt.rn.f16.f32 	%rs185, %f64;
	cvt.rn.f16.f32 	%rs186, %f63;
	mov.b32 	%r1403, {%rs186, %rs185};
	cvt.rn.f16.f32 	%rs187, %f62;
	cvt.rn.f16.f32 	%rs188, %f61;
	mov.b32 	%r1404, {%rs188, %rs187};
	cvt.rn.f16.f32 	%rs189, %f60;
	cvt.rn.f16.f32 	%rs190, %f59;
	mov.b32 	%r1405, {%rs190, %rs189};
	cvt.rn.f16.f32 	%rs191, %f58;
	cvt.rn.f16.f32 	%rs192, %f57;
	mov.b32 	%r1406, {%rs192, %rs191};
	.loc	1 179 34
	st.shared.v4.b32 	[%r37], {%r1394, %r1393, %r1392, %r1391};
	st.shared.v4.b32 	[%r38], {%r1398, %r1397, %r1396, %r1395};
	st.shared.v4.b32 	[%r39], {%r1402, %r1401, %r1400, %r1399};
	st.shared.v4.b32 	[%r40], {%r1406, %r1405, %r1404, %r1403};
	.loc	1 178 34
	bar.sync 	0;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r591, %r592, %r593, %r594 }, [ %r595 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r596, %r597, %r598, %r599 }, [ %r600 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r601, %r602, %r603, %r604 }, [ %r605 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r606, %r607, %r608, %r609 }, [ %r610 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r611, %r612, %r613, %r614 }, [ %r615 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r616, %r617, %r618, %r619 }, [ %r620 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r621, %r622, %r623, %r624 }, [ %r625 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r626, %r627, %r628, %r629 }, [ %r630 + 0 ];
	// end inline asm
	add.f16x2 	%r675, %r591, %r591;
	add.f16x2 	%r677, %r593, %r593;
	add.f16x2 	%r676, %r592, %r592;
	add.f16x2 	%r678, %r594, %r594;
	add.f16x2 	%r995, %r596, %r596;
	add.f16x2 	%r997, %r598, %r598;
	add.f16x2 	%r996, %r597, %r597;
	add.f16x2 	%r998, %r599, %r599;
	add.f16x2 	%r755, %r601, %r601;
	add.f16x2 	%r757, %r603, %r603;
	add.f16x2 	%r756, %r602, %r602;
	add.f16x2 	%r758, %r604, %r604;
	add.f16x2 	%r1075, %r606, %r606;
	add.f16x2 	%r1077, %r608, %r608;
	add.f16x2 	%r1076, %r607, %r607;
	add.f16x2 	%r1078, %r609, %r609;
	add.f16x2 	%r835, %r611, %r611;
	add.f16x2 	%r837, %r613, %r613;
	add.f16x2 	%r836, %r612, %r612;
	add.f16x2 	%r838, %r614, %r614;
	add.f16x2 	%r1155, %r616, %r616;
	add.f16x2 	%r1157, %r618, %r618;
	add.f16x2 	%r1156, %r617, %r617;
	add.f16x2 	%r1158, %r619, %r619;
	add.f16x2 	%r915, %r621, %r621;
	add.f16x2 	%r917, %r623, %r623;
	add.f16x2 	%r916, %r622, %r622;
	add.f16x2 	%r918, %r624, %r624;
	add.f16x2 	%r1235, %r626, %r626;
	add.f16x2 	%r1237, %r628, %r628;
	add.f16x2 	%r1236, %r627, %r627;
	add.f16x2 	%r1238, %r629, %r629;
	.loc	1 179 34
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 { %r631, %r632, %r633, %r634 }, [ %r635 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 { %r636, %r637, %r638, %r639 }, [ %r640 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 { %r641, %r642, %r643, %r644 }, [ %r645 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 { %r646, %r647, %r648, %r649 }, [ %r650 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 { %r651, %r652, %r653, %r654 }, [ %r655 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 { %r656, %r657, %r658, %r659 }, [ %r660 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 { %r661, %r662, %r663, %r664 }, [ %r665 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 { %r666, %r667, %r668, %r669 }, [ %r670 + 0 ];
	// end inline asm
	add.f16x2 	%r679, %r631, %r631;
	add.f16x2 	%r680, %r632, %r632;
	add.f16x2 	%r689, %r633, %r633;
	add.f16x2 	%r690, %r634, %r634;
	add.f16x2 	%r999, %r636, %r636;
	add.f16x2 	%r1000, %r637, %r637;
	add.f16x2 	%r1009, %r638, %r638;
	add.f16x2 	%r1010, %r639, %r639;
	add.f16x2 	%r699, %r641, %r641;
	add.f16x2 	%r700, %r642, %r642;
	add.f16x2 	%r709, %r643, %r643;
	add.f16x2 	%r710, %r644, %r644;
	add.f16x2 	%r1019, %r646, %r646;
	add.f16x2 	%r1020, %r647, %r647;
	add.f16x2 	%r1029, %r648, %r648;
	add.f16x2 	%r1030, %r649, %r649;
	add.f16x2 	%r719, %r651, %r651;
	add.f16x2 	%r720, %r652, %r652;
	add.f16x2 	%r729, %r653, %r653;
	add.f16x2 	%r730, %r654, %r654;
	add.f16x2 	%r1039, %r656, %r656;
	add.f16x2 	%r1040, %r657, %r657;
	add.f16x2 	%r1049, %r658, %r658;
	add.f16x2 	%r1050, %r659, %r659;
	add.f16x2 	%r739, %r661, %r661;
	add.f16x2 	%r740, %r662, %r662;
	add.f16x2 	%r749, %r663, %r663;
	add.f16x2 	%r750, %r664, %r664;
	add.f16x2 	%r1059, %r666, %r666;
	add.f16x2 	%r1060, %r667, %r667;
	add.f16x2 	%r1069, %r668, %r668;
	add.f16x2 	%r1070, %r669, %r669;
	.loc	1 181 35
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r1989, %r1988 }, { %r675, %r676, %r677, %r678 }, { %r679, %r680 }, { %r1989, %r1988 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r1987, %r1986 }, { %r675, %r676, %r677, %r678 }, { %r689, %r690 }, { %r1987, %r1986 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r1985, %r1984 }, { %r675, %r676, %r677, %r678 }, { %r699, %r700 }, { %r1985, %r1984 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r1983, %r1982 }, { %r675, %r676, %r677, %r678 }, { %r709, %r710 }, { %r1983, %r1982 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r1981, %r1980 }, { %r675, %r676, %r677, %r678 }, { %r719, %r720 }, { %r1981, %r1980 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r1979, %r1978 }, { %r675, %r676, %r677, %r678 }, { %r729, %r730 }, { %r1979, %r1978 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r1977, %r1976 }, { %r675, %r676, %r677, %r678 }, { %r739, %r740 }, { %r1977, %r1976 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r1975, %r1974 }, { %r675, %r676, %r677, %r678 }, { %r749, %r750 }, { %r1975, %r1974 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r1973, %r1972 }, { %r755, %r756, %r757, %r758 }, { %r679, %r680 }, { %r1973, %r1972 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r1971, %r1970 }, { %r755, %r756, %r757, %r758 }, { %r689, %r690 }, { %r1971, %r1970 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r1969, %r1968 }, { %r755, %r756, %r757, %r758 }, { %r699, %r700 }, { %r1969, %r1968 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r1967, %r1966 }, { %r755, %r756, %r757, %r758 }, { %r709, %r710 }, { %r1967, %r1966 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r1965, %r1964 }, { %r755, %r756, %r757, %r758 }, { %r719, %r720 }, { %r1965, %r1964 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r1963, %r1962 }, { %r755, %r756, %r757, %r758 }, { %r729, %r730 }, { %r1963, %r1962 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r1961, %r1960 }, { %r755, %r756, %r757, %r758 }, { %r739, %r740 }, { %r1961, %r1960 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r1959, %r1958 }, { %r755, %r756, %r757, %r758 }, { %r749, %r750 }, { %r1959, %r1958 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r1957, %r1956 }, { %r835, %r836, %r837, %r838 }, { %r679, %r680 }, { %r1957, %r1956 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r1955, %r1954 }, { %r835, %r836, %r837, %r838 }, { %r689, %r690 }, { %r1955, %r1954 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r1953, %r1952 }, { %r835, %r836, %r837, %r838 }, { %r699, %r700 }, { %r1953, %r1952 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r1951, %r1950 }, { %r835, %r836, %r837, %r838 }, { %r709, %r710 }, { %r1951, %r1950 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r1949, %r1948 }, { %r835, %r836, %r837, %r838 }, { %r719, %r720 }, { %r1949, %r1948 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r1947, %r1946 }, { %r835, %r836, %r837, %r838 }, { %r729, %r730 }, { %r1947, %r1946 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r1945, %r1944 }, { %r835, %r836, %r837, %r838 }, { %r739, %r740 }, { %r1945, %r1944 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r1943, %r1942 }, { %r835, %r836, %r837, %r838 }, { %r749, %r750 }, { %r1943, %r1942 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r1941, %r1940 }, { %r915, %r916, %r917, %r918 }, { %r679, %r680 }, { %r1941, %r1940 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r1939, %r1938 }, { %r915, %r916, %r917, %r918 }, { %r689, %r690 }, { %r1939, %r1938 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r1937, %r1936 }, { %r915, %r916, %r917, %r918 }, { %r699, %r700 }, { %r1937, %r1936 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r1935, %r1934 }, { %r915, %r916, %r917, %r918 }, { %r709, %r710 }, { %r1935, %r1934 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r1933, %r1932 }, { %r915, %r916, %r917, %r918 }, { %r719, %r720 }, { %r1933, %r1932 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r1931, %r1930 }, { %r915, %r916, %r917, %r918 }, { %r729, %r730 }, { %r1931, %r1930 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r1929, %r1928 }, { %r915, %r916, %r917, %r918 }, { %r739, %r740 }, { %r1929, %r1928 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r1927, %r1926 }, { %r915, %r916, %r917, %r918 }, { %r749, %r750 }, { %r1927, %r1926 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r1989, %r1988 }, { %r995, %r996, %r997, %r998 }, { %r999, %r1000 }, { %r1989, %r1988 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r1987, %r1986 }, { %r995, %r996, %r997, %r998 }, { %r1009, %r1010 }, { %r1987, %r1986 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r1985, %r1984 }, { %r995, %r996, %r997, %r998 }, { %r1019, %r1020 }, { %r1985, %r1984 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r1983, %r1982 }, { %r995, %r996, %r997, %r998 }, { %r1029, %r1030 }, { %r1983, %r1982 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r1981, %r1980 }, { %r995, %r996, %r997, %r998 }, { %r1039, %r1040 }, { %r1981, %r1980 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r1979, %r1978 }, { %r995, %r996, %r997, %r998 }, { %r1049, %r1050 }, { %r1979, %r1978 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r1977, %r1976 }, { %r995, %r996, %r997, %r998 }, { %r1059, %r1060 }, { %r1977, %r1976 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r1975, %r1974 }, { %r995, %r996, %r997, %r998 }, { %r1069, %r1070 }, { %r1975, %r1974 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r1973, %r1972 }, { %r1075, %r1076, %r1077, %r1078 }, { %r999, %r1000 }, { %r1973, %r1972 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r1971, %r1970 }, { %r1075, %r1076, %r1077, %r1078 }, { %r1009, %r1010 }, { %r1971, %r1970 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r1969, %r1968 }, { %r1075, %r1076, %r1077, %r1078 }, { %r1019, %r1020 }, { %r1969, %r1968 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r1967, %r1966 }, { %r1075, %r1076, %r1077, %r1078 }, { %r1029, %r1030 }, { %r1967, %r1966 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r1965, %r1964 }, { %r1075, %r1076, %r1077, %r1078 }, { %r1039, %r1040 }, { %r1965, %r1964 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r1963, %r1962 }, { %r1075, %r1076, %r1077, %r1078 }, { %r1049, %r1050 }, { %r1963, %r1962 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r1961, %r1960 }, { %r1075, %r1076, %r1077, %r1078 }, { %r1059, %r1060 }, { %r1961, %r1960 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r1959, %r1958 }, { %r1075, %r1076, %r1077, %r1078 }, { %r1069, %r1070 }, { %r1959, %r1958 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r1957, %r1956 }, { %r1155, %r1156, %r1157, %r1158 }, { %r999, %r1000 }, { %r1957, %r1956 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r1955, %r1954 }, { %r1155, %r1156, %r1157, %r1158 }, { %r1009, %r1010 }, { %r1955, %r1954 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r1953, %r1952 }, { %r1155, %r1156, %r1157, %r1158 }, { %r1019, %r1020 }, { %r1953, %r1952 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r1951, %r1950 }, { %r1155, %r1156, %r1157, %r1158 }, { %r1029, %r1030 }, { %r1951, %r1950 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r1949, %r1948 }, { %r1155, %r1156, %r1157, %r1158 }, { %r1039, %r1040 }, { %r1949, %r1948 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r1947, %r1946 }, { %r1155, %r1156, %r1157, %r1158 }, { %r1049, %r1050 }, { %r1947, %r1946 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r1945, %r1944 }, { %r1155, %r1156, %r1157, %r1158 }, { %r1059, %r1060 }, { %r1945, %r1944 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r1943, %r1942 }, { %r1155, %r1156, %r1157, %r1158 }, { %r1069, %r1070 }, { %r1943, %r1942 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r1941, %r1940 }, { %r1235, %r1236, %r1237, %r1238 }, { %r999, %r1000 }, { %r1941, %r1940 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r1939, %r1938 }, { %r1235, %r1236, %r1237, %r1238 }, { %r1009, %r1010 }, { %r1939, %r1938 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r1937, %r1936 }, { %r1235, %r1236, %r1237, %r1238 }, { %r1019, %r1020 }, { %r1937, %r1936 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r1935, %r1934 }, { %r1235, %r1236, %r1237, %r1238 }, { %r1029, %r1030 }, { %r1935, %r1934 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r1933, %r1932 }, { %r1235, %r1236, %r1237, %r1238 }, { %r1039, %r1040 }, { %r1933, %r1932 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r1931, %r1930 }, { %r1235, %r1236, %r1237, %r1238 }, { %r1049, %r1050 }, { %r1931, %r1930 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r1929, %r1928 }, { %r1235, %r1236, %r1237, %r1238 }, { %r1059, %r1060 }, { %r1929, %r1928 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16 { %r1927, %r1926 }, { %r1235, %r1236, %r1237, %r1238 }, { %r1069, %r1070 }, { %r1927, %r1926 };
	// end inline asm
	.loc	1 184 18
	add.s64 	%rd79, %rd136, %rd15;
	add.s64 	%rd80, %rd136, %rd14;
	add.s64 	%rd81, %rd136, %rd13;
	.loc	1 173 22
	add.s64 	%rd82, %rd136, %rd10;
	add.s32 	%r1535, %r1924, 1;
	setp.lt.s32 	%p52, %r1535, 3;
	selp.b32 	%r1924, %r1535, 0, %p52;
	.loc	1 176 54
	setp.lt.s32 	%p53, %r11, %r1920;
	.loc	1 176 23
	shl.b32 	%r1536, %r1924, 13;
	add.s32 	%r1538, %r433, %r1536;
	add.s32 	%r1311, %r1538, %r432;
	add.s32 	%r1313, %r1538, %r434;
	add.s32 	%r1315, %r1538, %r435;
	add.s32 	%r1317, %r1538, %r436;
	selp.b32 	%r1539, 16, 0, %p53;
	selp.b32 	%r1314, %r1539, 0, %p51;
	// begin inline asm
	@%p24 cp.async.cg.shared.global [ %r1311 + 0 ], [ %rd132 + 0 ], 0x10, %r1314;
	// end inline asm
	// begin inline asm
	@%p24 cp.async.cg.shared.global [ %r1313 + 0 ], [ %rd133 + 0 ], 0x10, %r1314;
	// end inline asm
	// begin inline asm
	@%p24 cp.async.cg.shared.global [ %r1315 + 0 ], [ %rd134 + 0 ], 0x10, %r1314;
	// end inline asm
	// begin inline asm
	@%p24 cp.async.cg.shared.global [ %r1317 + 0 ], [ %rd135 + 0 ], 0x10, %r1314;
	// end inline asm
	// begin inline asm
	cp.async.commit_group ;
	// end inline asm
	.loc	1 177 54
	setp.lt.s32 	%p54, %r6, %r1920;
	setp.lt.s32 	%p55, %r7, %r1920;
	setp.lt.s32 	%p56, %r8, %r1920;
	setp.lt.s32 	%p57, %r9, %r1920;
	.loc	1 177 23
	add.s32 	%r1541, %r439, %r1536;
	add.s32 	%r1319, %r1541, %r438;
	add.s32 	%r1321, %r1541, %r440;
	add.s32 	%r1323, %r1541, %r441;
	add.s32 	%r1325, %r1541, %r442;
	selp.b32 	%r1542, 16, 0, %p54;
	selp.b32 	%r1320, %r1542, 0, %p51;
	// begin inline asm
	@%p24 cp.async.cg.shared.global [ %r1319 + 0 ], [ %rd79 + 0 ], 0x10, %r1320;
	// end inline asm
	selp.b32 	%r1543, 16, 0, %p55;
	selp.b32 	%r1322, %r1543, 0, %p51;
	// begin inline asm
	@%p24 cp.async.cg.shared.global [ %r1321 + 0 ], [ %rd80 + 0 ], 0x10, %r1322;
	// end inline asm
	selp.b32 	%r1544, 16, 0, %p56;
	selp.b32 	%r1324, %r1544, 0, %p51;
	// begin inline asm
	@%p24 cp.async.cg.shared.global [ %r1323 + 0 ], [ %rd81 + 0 ], 0x10, %r1324;
	// end inline asm
	selp.b32 	%r1545, 16, 0, %p57;
	selp.b32 	%r1326, %r1545, 0, %p51;
	// begin inline asm
	@%p24 cp.async.cg.shared.global [ %r1325 + 0 ], [ %rd82 + 0 ], 0x10, %r1326;
	// end inline asm
	// begin inline asm
	cp.async.commit_group ;
	// end inline asm
	.loc	1 173 22
	add.s32 	%r1546, %r1923, 1;
	setp.lt.s32 	%p58, %r1546, 3;
	selp.b32 	%r1923, %r1546, 0, %p58;
	.loc	1 176 23
	shl.b32 	%r1547, %r1923, 13;
	add.s32 	%r1922, %r433, %r1547;
	// begin inline asm
	cp.async.wait_group 0x4;
	// end inline asm
	bar.sync 	0;
	.loc	1 177 23
	add.s32 	%r1921, %r439, %r1547;
	.loc	1 173 22
	add.s32 	%r1925, %r1925, 1;
	add.s64 	%rd136, %rd136, %rd12;
	add.s64 	%rd135, %rd135, 64;
	add.s64 	%rd134, %rd134, 64;
	add.s64 	%rd133, %rd133, 64;
	add.s64 	%rd132, %rd132, 64;
	add.s32 	%r1920, %r1920, -32;
	setp.lt.s32 	%p59, %r1925, %r14;
	@%p59 bra 	$L__BB0_3;
	.loc	1 186 19
	mov.b32 	%r1548, 872428544;
	mul.f16x2 	%r1991, %r1989, %r1548;
	mul.f16x2 	%r1992, %r1988, %r1548;
	mul.f16x2 	%r1993, %r1987, %r1548;
	mul.f16x2 	%r1994, %r1986, %r1548;
	mul.f16x2 	%r1995, %r1985, %r1548;
	mul.f16x2 	%r1996, %r1984, %r1548;
	mul.f16x2 	%r1997, %r1983, %r1548;
	mul.f16x2 	%r1998, %r1982, %r1548;
	mul.f16x2 	%r1999, %r1981, %r1548;
	mul.f16x2 	%r2000, %r1980, %r1548;
	mul.f16x2 	%r2001, %r1979, %r1548;
	mul.f16x2 	%r2002, %r1978, %r1548;
	mul.f16x2 	%r2003, %r1977, %r1548;
	mul.f16x2 	%r2004, %r1976, %r1548;
	mul.f16x2 	%r2005, %r1975, %r1548;
	mul.f16x2 	%r2006, %r1974, %r1548;
	mul.f16x2 	%r2007, %r1973, %r1548;
	mul.f16x2 	%r2008, %r1972, %r1548;
	mul.f16x2 	%r2009, %r1971, %r1548;
	mul.f16x2 	%r2010, %r1970, %r1548;
	mul.f16x2 	%r2011, %r1969, %r1548;
	mul.f16x2 	%r2012, %r1968, %r1548;
	mul.f16x2 	%r2013, %r1967, %r1548;
	mul.f16x2 	%r2014, %r1966, %r1548;
	mul.f16x2 	%r2015, %r1965, %r1548;
	mul.f16x2 	%r2016, %r1964, %r1548;
	mul.f16x2 	%r2017, %r1963, %r1548;
	mul.f16x2 	%r2018, %r1962, %r1548;
	mul.f16x2 	%r2019, %r1961, %r1548;
	mul.f16x2 	%r2020, %r1960, %r1548;
	mul.f16x2 	%r2021, %r1959, %r1548;
	mul.f16x2 	%r2022, %r1958, %r1548;
	mul.f16x2 	%r2023, %r1957, %r1548;
	mul.f16x2 	%r2024, %r1956, %r1548;
	mul.f16x2 	%r2025, %r1955, %r1548;
	mul.f16x2 	%r2026, %r1954, %r1548;
	mul.f16x2 	%r2027, %r1953, %r1548;
	mul.f16x2 	%r2028, %r1952, %r1548;
	mul.f16x2 	%r2029, %r1951, %r1548;
	mul.f16x2 	%r2030, %r1950, %r1548;
	mul.f16x2 	%r2031, %r1949, %r1548;
	mul.f16x2 	%r2032, %r1948, %r1548;
	mul.f16x2 	%r2033, %r1947, %r1548;
	mul.f16x2 	%r2034, %r1946, %r1548;
	mul.f16x2 	%r2035, %r1945, %r1548;
	mul.f16x2 	%r2036, %r1944, %r1548;
	mul.f16x2 	%r2037, %r1943, %r1548;
	mul.f16x2 	%r2038, %r1942, %r1548;
	mul.f16x2 	%r2039, %r1941, %r1548;
	mul.f16x2 	%r2040, %r1940, %r1548;
	mul.f16x2 	%r2041, %r1939, %r1548;
	mul.f16x2 	%r2042, %r1938, %r1548;
	mul.f16x2 	%r2043, %r1937, %r1548;
	mul.f16x2 	%r2044, %r1936, %r1548;
	mul.f16x2 	%r2045, %r1935, %r1548;
	mul.f16x2 	%r2046, %r1934, %r1548;
	mul.f16x2 	%r2047, %r1933, %r1548;
	mul.f16x2 	%r2048, %r1932, %r1548;
	mul.f16x2 	%r2049, %r1931, %r1548;
	mul.f16x2 	%r2050, %r1930, %r1548;
	mul.f16x2 	%r2051, %r1929, %r1548;
	mul.f16x2 	%r2052, %r1928, %r1548;
	mul.f16x2 	%r2053, %r1927, %r1548;
	mul.f16x2 	%r2054, %r1926, %r1548;
	bra.uni 	$L__BB0_5;
$L__BB0_1:
	.loc	1 187 33
	shr.u32 	%r1990, %r3, 4;
	mov.b32 	%r1991, 0;
	mov.u32 	%r1992, %r1991;
	mov.u32 	%r1993, %r1991;
	mov.u32 	%r1994, %r1991;
	mov.u32 	%r1995, %r1991;
	mov.u32 	%r1996, %r1991;
	mov.u32 	%r1997, %r1991;
	mov.u32 	%r1998, %r1991;
	mov.u32 	%r1999, %r1991;
	mov.u32 	%r2000, %r1991;
	mov.u32 	%r2001, %r1991;
	mov.u32 	%r2002, %r1991;
	mov.u32 	%r2003, %r1991;
	mov.u32 	%r2004, %r1991;
	mov.u32 	%r2005, %r1991;
	mov.u32 	%r2006, %r1991;
	mov.u32 	%r2007, %r1991;
	mov.u32 	%r2008, %r1991;
	mov.u32 	%r2009, %r1991;
	mov.u32 	%r2010, %r1991;
	mov.u32 	%r2011, %r1991;
	mov.u32 	%r2012, %r1991;
	mov.u32 	%r2013, %r1991;
	mov.u32 	%r2014, %r1991;
	mov.u32 	%r2015, %r1991;
	mov.u32 	%r2016, %r1991;
	mov.u32 	%r2017, %r1991;
	mov.u32 	%r2018, %r1991;
	mov.u32 	%r2019, %r1991;
	mov.u32 	%r2020, %r1991;
	mov.u32 	%r2021, %r1991;
	mov.u32 	%r2022, %r1991;
	mov.u32 	%r2023, %r1991;
	mov.u32 	%r2024, %r1991;
	mov.u32 	%r2025, %r1991;
	mov.u32 	%r2026, %r1991;
	mov.u32 	%r2027, %r1991;
	mov.u32 	%r2028, %r1991;
	mov.u32 	%r2029, %r1991;
	mov.u32 	%r2030, %r1991;
	mov.u32 	%r2031, %r1991;
	mov.u32 	%r2032, %r1991;
	mov.u32 	%r2033, %r1991;
	mov.u32 	%r2034, %r1991;
	mov.u32 	%r2035, %r1991;
	mov.u32 	%r2036, %r1991;
	mov.u32 	%r2037, %r1991;
	mov.u32 	%r2038, %r1991;
	mov.u32 	%r2039, %r1991;
	mov.u32 	%r2040, %r1991;
	mov.u32 	%r2041, %r1991;
	mov.u32 	%r2042, %r1991;
	mov.u32 	%r2043, %r1991;
	mov.u32 	%r2044, %r1991;
	mov.u32 	%r2045, %r1991;
	mov.u32 	%r2046, %r1991;
	mov.u32 	%r2047, %r1991;
	mov.u32 	%r2048, %r1991;
	mov.u32 	%r2049, %r1991;
	mov.u32 	%r2050, %r1991;
	mov.u32 	%r2051, %r1991;
	mov.u32 	%r2052, %r1991;
	mov.u32 	%r2053, %r1991;
	mov.u32 	%r2054, %r1991;
$L__BB0_5:
	.loc	1 154 51
	and.b32  	%r1741, %r5, 16;
	or.b32  	%r1742, %r1, %r6;
	.loc	1 154 38
	or.b32  	%r1743, %r1742, 120;
	.loc	1 163 33
	setp.lt.s32 	%p76, %r1743, %r328;
	.loc	1 163 58
	setp.lt.s32 	%p77, %r13, %r329;
	.loc	1 163 39
	and.pred  	%p75, %p76, %p77;
	.loc	1 154 38
	or.b32  	%r1744, %r1742, 112;
	.loc	1 163 33
	setp.lt.s32 	%p78, %r1744, %r328;
	.loc	1 163 39
	and.pred  	%p74, %p78, %p77;
	.loc	1 154 38
	or.b32  	%r1745, %r1742, 104;
	.loc	1 163 33
	setp.lt.s32 	%p79, %r1745, %r328;
	.loc	1 163 39
	and.pred  	%p73, %p79, %p77;
	.loc	1 154 38
	or.b32  	%r1746, %r1742, 96;
	.loc	1 163 33
	setp.lt.s32 	%p80, %r1746, %r328;
	.loc	1 163 39
	and.pred  	%p72, %p80, %p77;
	.loc	1 154 38
	or.b32  	%r1747, %r1742, 88;
	.loc	1 163 33
	setp.lt.s32 	%p81, %r1747, %r328;
	.loc	1 163 39
	and.pred  	%p71, %p81, %p77;
	.loc	1 154 38
	or.b32  	%r1748, %r1742, 80;
	.loc	1 163 33
	setp.lt.s32 	%p82, %r1748, %r328;
	.loc	1 163 39
	and.pred  	%p70, %p82, %p77;
	.loc	1 154 38
	or.b32  	%r1749, %r1742, 72;
	.loc	1 163 33
	setp.lt.s32 	%p83, %r1749, %r328;
	.loc	1 163 39
	and.pred  	%p69, %p83, %p77;
	.loc	1 154 38
	or.b32  	%r1750, %r1742, 64;
	.loc	1 163 33
	setp.lt.s32 	%p84, %r1750, %r328;
	.loc	1 163 39
	and.pred  	%p68, %p84, %p77;
	.loc	1 154 38
	or.b32  	%r1751, %r1742, 56;
	.loc	1 163 33
	setp.lt.s32 	%p85, %r1751, %r328;
	.loc	1 163 39
	and.pred  	%p67, %p85, %p77;
	.loc	1 154 38
	or.b32  	%r1752, %r1742, 48;
	.loc	1 163 33
	setp.lt.s32 	%p86, %r1752, %r328;
	.loc	1 163 39
	and.pred  	%p66, %p86, %p77;
	.loc	1 154 38
	or.b32  	%r1753, %r1742, 40;
	.loc	1 163 33
	setp.lt.s32 	%p87, %r1753, %r328;
	.loc	1 163 39
	and.pred  	%p65, %p87, %p77;
	.loc	1 154 38
	or.b32  	%r1754, %r1742, 32;
	.loc	1 163 33
	setp.lt.s32 	%p88, %r1754, %r328;
	.loc	1 163 39
	and.pred  	%p64, %p88, %p77;
	.loc	1 154 38
	or.b32  	%r1755, %r1, %r9;
	.loc	1 163 33
	setp.lt.s32 	%p89, %r1755, %r328;
	.loc	1 163 39
	and.pred  	%p63, %p89, %p77;
	.loc	1 154 38
	or.b32  	%r1756, %r1, %r8;
	.loc	1 163 33
	setp.lt.s32 	%p90, %r1756, %r328;
	.loc	1 163 39
	and.pred  	%p62, %p90, %p77;
	.loc	1 154 38
	or.b32  	%r1757, %r1, %r7;
	.loc	1 163 33
	setp.lt.s32 	%p91, %r1757, %r328;
	.loc	1 163 39
	and.pred  	%p61, %p91, %p77;
	.loc	1 163 33
	setp.lt.s32 	%p92, %r1742, %r328;
	.loc	1 163 39
	and.pred  	%p60, %p92, %p77;
	.loc	1 162 33
	mul.lo.s32 	%r1758, %r1743, %r331;
	.loc	1 162 21
	mul.wide.s32 	%rd99, %r1758, 2;
	add.s64 	%rd100, %rd32, %rd99;
	.loc	1 162 52
	mul.wide.s32 	%rd101, %r13, 2;
	add.s64 	%rd98, %rd100, %rd101;
	.loc	1 162 33
	shl.b32 	%r1759, %r331, 3;
	sub.s32 	%r1760, %r1758, %r1759;
	.loc	1 162 21
	mul.wide.s32 	%rd102, %r1760, 2;
	add.s64 	%rd103, %rd32, %rd102;
	.loc	1 162 52
	add.s64 	%rd97, %rd103, %rd101;
	.loc	1 162 33
	sub.s32 	%r1761, %r1760, %r1759;
	.loc	1 162 21
	mul.wide.s32 	%rd104, %r1761, 2;
	add.s64 	%rd105, %rd32, %rd104;
	.loc	1 162 52
	add.s64 	%rd96, %rd105, %rd101;
	.loc	1 162 33
	sub.s32 	%r1762, %r1761, %r1759;
	.loc	1 162 21
	mul.wide.s32 	%rd106, %r1762, 2;
	add.s64 	%rd107, %rd32, %rd106;
	.loc	1 162 52
	add.s64 	%rd95, %rd107, %rd101;
	.loc	1 162 33
	sub.s32 	%r1763, %r1762, %r1759;
	.loc	1 162 21
	mul.wide.s32 	%rd108, %r1763, 2;
	add.s64 	%rd109, %rd32, %rd108;
	.loc	1 162 52
	add.s64 	%rd94, %rd109, %rd101;
	.loc	1 162 33
	sub.s32 	%r1764, %r1763, %r1759;
	.loc	1 162 21
	mul.wide.s32 	%rd110, %r1764, 2;
	add.s64 	%rd111, %rd32, %rd110;
	.loc	1 162 52
	add.s64 	%rd93, %rd111, %rd101;
	.loc	1 162 33
	sub.s32 	%r1765, %r1764, %r1759;
	.loc	1 162 21
	mul.wide.s32 	%rd112, %r1765, 2;
	add.s64 	%rd113, %rd32, %rd112;
	.loc	1 162 52
	add.s64 	%rd92, %rd113, %rd101;
	.loc	1 162 33
	sub.s32 	%r1766, %r1765, %r1759;
	.loc	1 162 21
	mul.wide.s32 	%rd114, %r1766, 2;
	add.s64 	%rd115, %rd32, %rd114;
	.loc	1 162 52
	add.s64 	%rd91, %rd115, %rd101;
	.loc	1 162 33
	sub.s32 	%r1767, %r1766, %r1759;
	.loc	1 162 21
	mul.wide.s32 	%rd116, %r1767, 2;
	add.s64 	%rd117, %rd32, %rd116;
	.loc	1 162 52
	add.s64 	%rd90, %rd117, %rd101;
	.loc	1 162 33
	sub.s32 	%r1768, %r1767, %r1759;
	.loc	1 162 21
	mul.wide.s32 	%rd118, %r1768, 2;
	add.s64 	%rd119, %rd32, %rd118;
	.loc	1 162 52
	add.s64 	%rd89, %rd119, %rd101;
	.loc	1 162 33
	sub.s32 	%r1769, %r1768, %r1759;
	.loc	1 162 21
	mul.wide.s32 	%rd120, %r1769, 2;
	add.s64 	%rd121, %rd32, %rd120;
	.loc	1 162 52
	add.s64 	%rd88, %rd121, %rd101;
	.loc	1 162 33
	sub.s32 	%r1770, %r1769, %r1759;
	.loc	1 162 21
	mul.wide.s32 	%rd122, %r1770, 2;
	add.s64 	%rd123, %rd32, %rd122;
	.loc	1 162 52
	add.s64 	%rd87, %rd123, %rd101;
	.loc	1 162 33
	mul.lo.s32 	%r1771, %r1755, %r331;
	.loc	1 162 21
	mul.wide.s32 	%rd124, %r1771, 2;
	add.s64 	%rd125, %rd32, %rd124;
	.loc	1 162 52
	add.s64 	%rd86, %rd125, %rd101;
	.loc	1 162 33
	mul.lo.s32 	%r1772, %r1756, %r331;
	.loc	1 162 21
	mul.wide.s32 	%rd126, %r1772, 2;
	add.s64 	%rd127, %rd32, %rd126;
	.loc	1 162 52
	add.s64 	%rd85, %rd127, %rd101;
	.loc	1 162 33
	mul.lo.s32 	%r1773, %r1757, %r331;
	.loc	1 162 21
	mul.wide.s32 	%rd128, %r1773, 2;
	add.s64 	%rd129, %rd32, %rd128;
	.loc	1 162 52
	add.s64 	%rd84, %rd129, %rd101;
	.loc	1 162 33
	mul.lo.s32 	%r1774, %r1742, %r331;
	.loc	1 162 21
	mul.wide.s32 	%rd130, %r1774, 2;
	add.s64 	%rd131, %rd32, %rd130;
	.loc	1 162 52
	add.s64 	%rd83, %rd131, %rd101;
	.loc	1 173 22
	// begin inline asm
	cp.async.wait_group 0x0;
	// end inline asm
	bar.sync 	0;
	.loc	1 187 33
	shr.u32 	%r1775, %r3, 2;
	shl.b32 	%r1776, %r2, 1;
	and.b32  	%r1777, %r1776, 6;
	or.b32  	%r1778, %r1775, %r1741;
	shl.b32 	%r1779, %r4, 3;
	and.b32  	%r1780, %r1779, 8;
	or.b32  	%r1781, %r1780, %r1777;
	mad.lo.s32 	%r1782, %r1778, 136, %r1781;
	shl.b32 	%r1783, %r1782, 1;
	add.s32 	%r1785, %r433, %r1783;
	st.shared.b32 	[%r1785], %r1991;
	st.shared.b32 	[%r1785+2176], %r1992;
	st.shared.b32 	[%r1785+32], %r1993;
	st.shared.b32 	[%r1785+2208], %r1994;
	st.shared.b32 	[%r1785+64], %r1995;
	st.shared.b32 	[%r1785+2240], %r1996;
	st.shared.b32 	[%r1785+96], %r1997;
	st.shared.b32 	[%r1785+2272], %r1998;
	st.shared.b32 	[%r1785+128], %r1999;
	st.shared.b32 	[%r1785+2304], %r2000;
	st.shared.b32 	[%r1785+160], %r2001;
	st.shared.b32 	[%r1785+2336], %r2002;
	st.shared.b32 	[%r1785+192], %r2003;
	st.shared.b32 	[%r1785+2368], %r2004;
	st.shared.b32 	[%r1785+224], %r2005;
	st.shared.b32 	[%r1785+2400], %r2006;
	bar.sync 	0;
	shl.b32 	%r1786, %r4, 1;
	and.b32  	%r1787, %r1786, 6;
	or.b32  	%r1788, %r1787, %r1990;
	mad.lo.s32 	%r1789, %r1788, 136, %r12;
	shl.b32 	%r1790, %r1789, 1;
	add.s32 	%r1791, %r433, %r1790;
	ld.shared.v4.b32 	{%r1792, %r1793, %r1794, %r1795}, [%r1791];
	mov.b32 	{%rs321, %rs322}, %r1795;
	mov.b32 	{%rs323, %rs324}, %r1794;
	mov.b32 	{%rs325, %rs326}, %r1793;
	mov.b32 	{%rs327, %rs328}, %r1792;
	ld.shared.v4.b32 	{%r1796, %r1797, %r1798, %r1799}, [%r1791+2176];
	mov.b32 	{%rs329, %rs330}, %r1799;
	mov.b32 	{%rs331, %rs332}, %r1798;
	mov.b32 	{%rs333, %rs334}, %r1797;
	mov.b32 	{%rs335, %rs336}, %r1796;
	ld.shared.v4.b32 	{%r1800, %r1801, %r1802, %r1803}, [%r1791+4352];
	mov.b32 	{%rs337, %rs338}, %r1803;
	mov.b32 	{%rs339, %rs340}, %r1802;
	mov.b32 	{%rs341, %rs342}, %r1801;
	mov.b32 	{%rs343, %rs344}, %r1800;
	ld.shared.v4.b32 	{%r1804, %r1805, %r1806, %r1807}, [%r1791+6528];
	mov.b32 	{%rs345, %rs346}, %r1807;
	mov.b32 	{%rs347, %rs348}, %r1806;
	mov.b32 	{%rs349, %rs350}, %r1805;
	mov.b32 	{%rs351, %rs352}, %r1804;
	bar.sync 	0;
	st.shared.b32 	[%r1785], %r2007;
	st.shared.b32 	[%r1785+2176], %r2008;
	st.shared.b32 	[%r1785+32], %r2009;
	st.shared.b32 	[%r1785+2208], %r2010;
	st.shared.b32 	[%r1785+64], %r2011;
	st.shared.b32 	[%r1785+2240], %r2012;
	st.shared.b32 	[%r1785+96], %r2013;
	st.shared.b32 	[%r1785+2272], %r2014;
	st.shared.b32 	[%r1785+128], %r2015;
	st.shared.b32 	[%r1785+2304], %r2016;
	st.shared.b32 	[%r1785+160], %r2017;
	st.shared.b32 	[%r1785+2336], %r2018;
	st.shared.b32 	[%r1785+192], %r2019;
	st.shared.b32 	[%r1785+2368], %r2020;
	st.shared.b32 	[%r1785+224], %r2021;
	st.shared.b32 	[%r1785+2400], %r2022;
	bar.sync 	0;
	ld.shared.v4.b32 	{%r1808, %r1809, %r1810, %r1811}, [%r1791];
	mov.b32 	{%rs353, %rs354}, %r1811;
	mov.b32 	{%rs355, %rs356}, %r1810;
	mov.b32 	{%rs357, %rs358}, %r1809;
	mov.b32 	{%rs359, %rs360}, %r1808;
	ld.shared.v4.b32 	{%r1812, %r1813, %r1814, %r1815}, [%r1791+2176];
	mov.b32 	{%rs361, %rs362}, %r1815;
	mov.b32 	{%rs363, %rs364}, %r1814;
	mov.b32 	{%rs365, %rs366}, %r1813;
	mov.b32 	{%rs367, %rs368}, %r1812;
	ld.shared.v4.b32 	{%r1816, %r1817, %r1818, %r1819}, [%r1791+4352];
	mov.b32 	{%rs369, %rs370}, %r1819;
	mov.b32 	{%rs371, %rs372}, %r1818;
	mov.b32 	{%rs373, %rs374}, %r1817;
	mov.b32 	{%rs375, %rs376}, %r1816;
	ld.shared.v4.b32 	{%r1820, %r1821, %r1822, %r1823}, [%r1791+6528];
	mov.b32 	{%rs377, %rs378}, %r1823;
	mov.b32 	{%rs379, %rs380}, %r1822;
	mov.b32 	{%rs381, %rs382}, %r1821;
	mov.b32 	{%rs383, %rs384}, %r1820;
	bar.sync 	0;
	st.shared.b32 	[%r1785], %r2023;
	st.shared.b32 	[%r1785+2176], %r2024;
	st.shared.b32 	[%r1785+32], %r2025;
	st.shared.b32 	[%r1785+2208], %r2026;
	st.shared.b32 	[%r1785+64], %r2027;
	st.shared.b32 	[%r1785+2240], %r2028;
	st.shared.b32 	[%r1785+96], %r2029;
	st.shared.b32 	[%r1785+2272], %r2030;
	st.shared.b32 	[%r1785+128], %r2031;
	st.shared.b32 	[%r1785+2304], %r2032;
	st.shared.b32 	[%r1785+160], %r2033;
	st.shared.b32 	[%r1785+2336], %r2034;
	st.shared.b32 	[%r1785+192], %r2035;
	st.shared.b32 	[%r1785+2368], %r2036;
	st.shared.b32 	[%r1785+224], %r2037;
	st.shared.b32 	[%r1785+2400], %r2038;
	bar.sync 	0;
	ld.shared.v4.b32 	{%r1824, %r1825, %r1826, %r1827}, [%r1791];
	mov.b32 	{%rs385, %rs386}, %r1827;
	mov.b32 	{%rs387, %rs388}, %r1826;
	mov.b32 	{%rs389, %rs390}, %r1825;
	mov.b32 	{%rs391, %rs392}, %r1824;
	ld.shared.v4.b32 	{%r1828, %r1829, %r1830, %r1831}, [%r1791+2176];
	mov.b32 	{%rs393, %rs394}, %r1831;
	mov.b32 	{%rs395, %rs396}, %r1830;
	mov.b32 	{%rs397, %rs398}, %r1829;
	mov.b32 	{%rs399, %rs400}, %r1828;
	ld.shared.v4.b32 	{%r1832, %r1833, %r1834, %r1835}, [%r1791+4352];
	mov.b32 	{%rs401, %rs402}, %r1835;
	mov.b32 	{%rs403, %rs404}, %r1834;
	mov.b32 	{%rs405, %rs406}, %r1833;
	mov.b32 	{%rs407, %rs408}, %r1832;
	ld.shared.v4.b32 	{%r1836, %r1837, %r1838, %r1839}, [%r1791+6528];
	mov.b32 	{%rs409, %rs410}, %r1839;
	mov.b32 	{%rs411, %rs412}, %r1838;
	mov.b32 	{%rs413, %rs414}, %r1837;
	mov.b32 	{%rs415, %rs416}, %r1836;
	bar.sync 	0;
	st.shared.b32 	[%r1785], %r2039;
	st.shared.b32 	[%r1785+2176], %r2040;
	st.shared.b32 	[%r1785+32], %r2041;
	st.shared.b32 	[%r1785+2208], %r2042;
	st.shared.b32 	[%r1785+64], %r2043;
	st.shared.b32 	[%r1785+2240], %r2044;
	st.shared.b32 	[%r1785+96], %r2045;
	st.shared.b32 	[%r1785+2272], %r2046;
	st.shared.b32 	[%r1785+128], %r2047;
	st.shared.b32 	[%r1785+2304], %r2048;
	st.shared.b32 	[%r1785+160], %r2049;
	st.shared.b32 	[%r1785+2336], %r2050;
	st.shared.b32 	[%r1785+192], %r2051;
	st.shared.b32 	[%r1785+2368], %r2052;
	st.shared.b32 	[%r1785+224], %r2053;
	st.shared.b32 	[%r1785+2400], %r2054;
	bar.sync 	0;
	ld.shared.v4.b32 	{%r1840, %r1841, %r1842, %r1843}, [%r1791];
	mov.b32 	{%rs417, %rs418}, %r1843;
	mov.b32 	{%rs419, %rs420}, %r1842;
	mov.b32 	{%rs421, %rs422}, %r1841;
	mov.b32 	{%rs423, %rs424}, %r1840;
	ld.shared.v4.b32 	{%r1844, %r1845, %r1846, %r1847}, [%r1791+2176];
	mov.b32 	{%rs425, %rs426}, %r1847;
	mov.b32 	{%rs427, %rs428}, %r1846;
	mov.b32 	{%rs429, %rs430}, %r1845;
	mov.b32 	{%rs431, %rs432}, %r1844;
	ld.shared.v4.b32 	{%r1848, %r1849, %r1850, %r1851}, [%r1791+4352];
	mov.b32 	{%rs433, %rs434}, %r1851;
	mov.b32 	{%rs435, %rs436}, %r1850;
	mov.b32 	{%rs437, %rs438}, %r1849;
	mov.b32 	{%rs439, %rs440}, %r1848;
	ld.shared.v4.b32 	{%r1852, %r1853, %r1854, %r1855}, [%r1791+6528];
	mov.b32 	{%rs441, %rs442}, %r1855;
	mov.b32 	{%rs443, %rs444}, %r1854;
	mov.b32 	{%rs445, %rs446}, %r1853;
	mov.b32 	{%rs447, %rs448}, %r1852;
	cvt.f32.f16 	%f65, %rs327;
	cvt.f32.f16 	%f66, %rs328;
	cvt.f32.f16 	%f67, %rs325;
	cvt.f32.f16 	%f68, %rs326;
	cvt.f32.f16 	%f69, %rs323;
	cvt.f32.f16 	%f70, %rs324;
	cvt.f32.f16 	%f71, %rs321;
	cvt.f32.f16 	%f72, %rs322;
	cvt.f32.f16 	%f73, %rs335;
	cvt.f32.f16 	%f74, %rs336;
	cvt.f32.f16 	%f75, %rs333;
	cvt.f32.f16 	%f76, %rs334;
	cvt.f32.f16 	%f77, %rs331;
	cvt.f32.f16 	%f78, %rs332;
	cvt.f32.f16 	%f79, %rs329;
	cvt.f32.f16 	%f80, %rs330;
	cvt.f32.f16 	%f81, %rs343;
	cvt.f32.f16 	%f82, %rs344;
	cvt.f32.f16 	%f83, %rs341;
	cvt.f32.f16 	%f84, %rs342;
	cvt.f32.f16 	%f85, %rs339;
	cvt.f32.f16 	%f86, %rs340;
	cvt.f32.f16 	%f87, %rs337;
	cvt.f32.f16 	%f88, %rs338;
	cvt.f32.f16 	%f89, %rs351;
	cvt.f32.f16 	%f90, %rs352;
	cvt.f32.f16 	%f91, %rs349;
	cvt.f32.f16 	%f92, %rs350;
	cvt.f32.f16 	%f93, %rs347;
	cvt.f32.f16 	%f94, %rs348;
	cvt.f32.f16 	%f95, %rs345;
	cvt.f32.f16 	%f96, %rs346;
	cvt.f32.f16 	%f97, %rs359;
	cvt.f32.f16 	%f98, %rs360;
	cvt.f32.f16 	%f99, %rs357;
	cvt.f32.f16 	%f100, %rs358;
	cvt.f32.f16 	%f101, %rs355;
	cvt.f32.f16 	%f102, %rs356;
	cvt.f32.f16 	%f103, %rs353;
	cvt.f32.f16 	%f104, %rs354;
	cvt.f32.f16 	%f105, %rs367;
	cvt.f32.f16 	%f106, %rs368;
	cvt.f32.f16 	%f107, %rs365;
	cvt.f32.f16 	%f108, %rs366;
	cvt.f32.f16 	%f109, %rs363;
	cvt.f32.f16 	%f110, %rs364;
	cvt.f32.f16 	%f111, %rs361;
	cvt.f32.f16 	%f112, %rs362;
	cvt.f32.f16 	%f113, %rs375;
	cvt.f32.f16 	%f114, %rs376;
	cvt.f32.f16 	%f115, %rs373;
	cvt.f32.f16 	%f116, %rs374;
	cvt.f32.f16 	%f117, %rs371;
	cvt.f32.f16 	%f118, %rs372;
	cvt.f32.f16 	%f119, %rs369;
	cvt.f32.f16 	%f120, %rs370;
	cvt.f32.f16 	%f121, %rs383;
	cvt.f32.f16 	%f122, %rs384;
	cvt.f32.f16 	%f123, %rs381;
	cvt.f32.f16 	%f124, %rs382;
	cvt.f32.f16 	%f125, %rs379;
	cvt.f32.f16 	%f126, %rs380;
	cvt.f32.f16 	%f127, %rs377;
	cvt.f32.f16 	%f128, %rs378;
	cvt.f32.f16 	%f129, %rs391;
	cvt.f32.f16 	%f130, %rs392;
	cvt.f32.f16 	%f131, %rs389;
	cvt.f32.f16 	%f132, %rs390;
	cvt.f32.f16 	%f133, %rs387;
	cvt.f32.f16 	%f134, %rs388;
	cvt.f32.f16 	%f135, %rs385;
	cvt.f32.f16 	%f136, %rs386;
	cvt.f32.f16 	%f137, %rs399;
	cvt.f32.f16 	%f138, %rs400;
	cvt.f32.f16 	%f139, %rs397;
	cvt.f32.f16 	%f140, %rs398;
	cvt.f32.f16 	%f141, %rs395;
	cvt.f32.f16 	%f142, %rs396;
	cvt.f32.f16 	%f143, %rs393;
	cvt.f32.f16 	%f144, %rs394;
	cvt.f32.f16 	%f145, %rs407;
	cvt.f32.f16 	%f146, %rs408;
	cvt.f32.f16 	%f147, %rs405;
	cvt.f32.f16 	%f148, %rs406;
	cvt.f32.f16 	%f149, %rs403;
	cvt.f32.f16 	%f150, %rs404;
	cvt.f32.f16 	%f151, %rs401;
	cvt.f32.f16 	%f152, %rs402;
	cvt.f32.f16 	%f153, %rs415;
	cvt.f32.f16 	%f154, %rs416;
	cvt.f32.f16 	%f155, %rs413;
	cvt.f32.f16 	%f156, %rs414;
	cvt.f32.f16 	%f157, %rs411;
	cvt.f32.f16 	%f158, %rs412;
	cvt.f32.f16 	%f159, %rs409;
	cvt.f32.f16 	%f160, %rs410;
	cvt.f32.f16 	%f161, %rs423;
	cvt.f32.f16 	%f162, %rs424;
	cvt.f32.f16 	%f163, %rs421;
	cvt.f32.f16 	%f164, %rs422;
	cvt.f32.f16 	%f165, %rs419;
	cvt.f32.f16 	%f166, %rs420;
	cvt.f32.f16 	%f167, %rs417;
	cvt.f32.f16 	%f168, %rs418;
	cvt.f32.f16 	%f169, %rs431;
	cvt.f32.f16 	%f170, %rs432;
	cvt.f32.f16 	%f171, %rs429;
	cvt.f32.f16 	%f172, %rs430;
	cvt.f32.f16 	%f173, %rs427;
	cvt.f32.f16 	%f174, %rs428;
	cvt.f32.f16 	%f175, %rs425;
	cvt.f32.f16 	%f176, %rs426;
	cvt.f32.f16 	%f177, %rs439;
	cvt.f32.f16 	%f178, %rs440;
	cvt.f32.f16 	%f179, %rs437;
	cvt.f32.f16 	%f180, %rs438;
	cvt.f32.f16 	%f181, %rs435;
	cvt.f32.f16 	%f182, %rs436;
	cvt.f32.f16 	%f183, %rs433;
	cvt.f32.f16 	%f184, %rs434;
	cvt.f32.f16 	%f185, %rs447;
	cvt.f32.f16 	%f186, %rs448;
	cvt.f32.f16 	%f187, %rs445;
	cvt.f32.f16 	%f188, %rs446;
	cvt.f32.f16 	%f189, %rs443;
	cvt.f32.f16 	%f190, %rs444;
	cvt.f32.f16 	%f191, %rs441;
	cvt.f32.f16 	%f192, %rs442;
	mov.b32 	%r1549, %f65;
	// begin inline asm
	cvt.rn.bf16.f32 %rs193, %r1549;
	// end inline asm
	mov.b32 	%r1550, %f66;
	// begin inline asm
	cvt.rn.bf16.f32 %rs194, %r1550;
	// end inline asm
	mov.b32 	%r1551, %f67;
	// begin inline asm
	cvt.rn.bf16.f32 %rs195, %r1551;
	// end inline asm
	mov.b32 	%r1552, %f68;
	// begin inline asm
	cvt.rn.bf16.f32 %rs196, %r1552;
	// end inline asm
	mov.b32 	%r1553, %f69;
	// begin inline asm
	cvt.rn.bf16.f32 %rs197, %r1553;
	// end inline asm
	mov.b32 	%r1554, %f70;
	// begin inline asm
	cvt.rn.bf16.f32 %rs198, %r1554;
	// end inline asm
	mov.b32 	%r1555, %f71;
	// begin inline asm
	cvt.rn.bf16.f32 %rs199, %r1555;
	// end inline asm
	mov.b32 	%r1556, %f72;
	// begin inline asm
	cvt.rn.bf16.f32 %rs200, %r1556;
	// end inline asm
	mov.b32 	%r1557, %f73;
	// begin inline asm
	cvt.rn.bf16.f32 %rs201, %r1557;
	// end inline asm
	mov.b32 	%r1558, %f74;
	// begin inline asm
	cvt.rn.bf16.f32 %rs202, %r1558;
	// end inline asm
	mov.b32 	%r1559, %f75;
	// begin inline asm
	cvt.rn.bf16.f32 %rs203, %r1559;
	// end inline asm
	mov.b32 	%r1560, %f76;
	// begin inline asm
	cvt.rn.bf16.f32 %rs204, %r1560;
	// end inline asm
	mov.b32 	%r1561, %f77;
	// begin inline asm
	cvt.rn.bf16.f32 %rs205, %r1561;
	// end inline asm
	mov.b32 	%r1562, %f78;
	// begin inline asm
	cvt.rn.bf16.f32 %rs206, %r1562;
	// end inline asm
	mov.b32 	%r1563, %f79;
	// begin inline asm
	cvt.rn.bf16.f32 %rs207, %r1563;
	// end inline asm
	mov.b32 	%r1564, %f80;
	// begin inline asm
	cvt.rn.bf16.f32 %rs208, %r1564;
	// end inline asm
	mov.b32 	%r1565, %f81;
	// begin inline asm
	cvt.rn.bf16.f32 %rs209, %r1565;
	// end inline asm
	mov.b32 	%r1566, %f82;
	// begin inline asm
	cvt.rn.bf16.f32 %rs210, %r1566;
	// end inline asm
	mov.b32 	%r1567, %f83;
	// begin inline asm
	cvt.rn.bf16.f32 %rs211, %r1567;
	// end inline asm
	mov.b32 	%r1568, %f84;
	// begin inline asm
	cvt.rn.bf16.f32 %rs212, %r1568;
	// end inline asm
	mov.b32 	%r1569, %f85;
	// begin inline asm
	cvt.rn.bf16.f32 %rs213, %r1569;
	// end inline asm
	mov.b32 	%r1570, %f86;
	// begin inline asm
	cvt.rn.bf16.f32 %rs214, %r1570;
	// end inline asm
	mov.b32 	%r1571, %f87;
	// begin inline asm
	cvt.rn.bf16.f32 %rs215, %r1571;
	// end inline asm
	mov.b32 	%r1572, %f88;
	// begin inline asm
	cvt.rn.bf16.f32 %rs216, %r1572;
	// end inline asm
	mov.b32 	%r1573, %f89;
	// begin inline asm
	cvt.rn.bf16.f32 %rs217, %r1573;
	// end inline asm
	mov.b32 	%r1574, %f90;
	// begin inline asm
	cvt.rn.bf16.f32 %rs218, %r1574;
	// end inline asm
	mov.b32 	%r1575, %f91;
	// begin inline asm
	cvt.rn.bf16.f32 %rs219, %r1575;
	// end inline asm
	mov.b32 	%r1576, %f92;
	// begin inline asm
	cvt.rn.bf16.f32 %rs220, %r1576;
	// end inline asm
	mov.b32 	%r1577, %f93;
	// begin inline asm
	cvt.rn.bf16.f32 %rs221, %r1577;
	// end inline asm
	mov.b32 	%r1578, %f94;
	// begin inline asm
	cvt.rn.bf16.f32 %rs222, %r1578;
	// end inline asm
	mov.b32 	%r1579, %f95;
	// begin inline asm
	cvt.rn.bf16.f32 %rs223, %r1579;
	// end inline asm
	mov.b32 	%r1580, %f96;
	// begin inline asm
	cvt.rn.bf16.f32 %rs224, %r1580;
	// end inline asm
	mov.b32 	%r1581, %f97;
	// begin inline asm
	cvt.rn.bf16.f32 %rs225, %r1581;
	// end inline asm
	mov.b32 	%r1582, %f98;
	// begin inline asm
	cvt.rn.bf16.f32 %rs226, %r1582;
	// end inline asm
	mov.b32 	%r1583, %f99;
	// begin inline asm
	cvt.rn.bf16.f32 %rs227, %r1583;
	// end inline asm
	mov.b32 	%r1584, %f100;
	// begin inline asm
	cvt.rn.bf16.f32 %rs228, %r1584;
	// end inline asm
	mov.b32 	%r1585, %f101;
	// begin inline asm
	cvt.rn.bf16.f32 %rs229, %r1585;
	// end inline asm
	mov.b32 	%r1586, %f102;
	// begin inline asm
	cvt.rn.bf16.f32 %rs230, %r1586;
	// end inline asm
	mov.b32 	%r1587, %f103;
	// begin inline asm
	cvt.rn.bf16.f32 %rs231, %r1587;
	// end inline asm
	mov.b32 	%r1588, %f104;
	// begin inline asm
	cvt.rn.bf16.f32 %rs232, %r1588;
	// end inline asm
	mov.b32 	%r1589, %f105;
	// begin inline asm
	cvt.rn.bf16.f32 %rs233, %r1589;
	// end inline asm
	mov.b32 	%r1590, %f106;
	// begin inline asm
	cvt.rn.bf16.f32 %rs234, %r1590;
	// end inline asm
	mov.b32 	%r1591, %f107;
	// begin inline asm
	cvt.rn.bf16.f32 %rs235, %r1591;
	// end inline asm
	mov.b32 	%r1592, %f108;
	// begin inline asm
	cvt.rn.bf16.f32 %rs236, %r1592;
	// end inline asm
	mov.b32 	%r1593, %f109;
	// begin inline asm
	cvt.rn.bf16.f32 %rs237, %r1593;
	// end inline asm
	mov.b32 	%r1594, %f110;
	// begin inline asm
	cvt.rn.bf16.f32 %rs238, %r1594;
	// end inline asm
	mov.b32 	%r1595, %f111;
	// begin inline asm
	cvt.rn.bf16.f32 %rs239, %r1595;
	// end inline asm
	mov.b32 	%r1596, %f112;
	// begin inline asm
	cvt.rn.bf16.f32 %rs240, %r1596;
	// end inline asm
	mov.b32 	%r1597, %f113;
	// begin inline asm
	cvt.rn.bf16.f32 %rs241, %r1597;
	// end inline asm
	mov.b32 	%r1598, %f114;
	// begin inline asm
	cvt.rn.bf16.f32 %rs242, %r1598;
	// end inline asm
	mov.b32 	%r1599, %f115;
	// begin inline asm
	cvt.rn.bf16.f32 %rs243, %r1599;
	// end inline asm
	mov.b32 	%r1600, %f116;
	// begin inline asm
	cvt.rn.bf16.f32 %rs244, %r1600;
	// end inline asm
	mov.b32 	%r1601, %f117;
	// begin inline asm
	cvt.rn.bf16.f32 %rs245, %r1601;
	// end inline asm
	mov.b32 	%r1602, %f118;
	// begin inline asm
	cvt.rn.bf16.f32 %rs246, %r1602;
	// end inline asm
	mov.b32 	%r1603, %f119;
	// begin inline asm
	cvt.rn.bf16.f32 %rs247, %r1603;
	// end inline asm
	mov.b32 	%r1604, %f120;
	// begin inline asm
	cvt.rn.bf16.f32 %rs248, %r1604;
	// end inline asm
	mov.b32 	%r1605, %f121;
	// begin inline asm
	cvt.rn.bf16.f32 %rs249, %r1605;
	// end inline asm
	mov.b32 	%r1606, %f122;
	// begin inline asm
	cvt.rn.bf16.f32 %rs250, %r1606;
	// end inline asm
	mov.b32 	%r1607, %f123;
	// begin inline asm
	cvt.rn.bf16.f32 %rs251, %r1607;
	// end inline asm
	mov.b32 	%r1608, %f124;
	// begin inline asm
	cvt.rn.bf16.f32 %rs252, %r1608;
	// end inline asm
	mov.b32 	%r1609, %f125;
	// begin inline asm
	cvt.rn.bf16.f32 %rs253, %r1609;
	// end inline asm
	mov.b32 	%r1610, %f126;
	// begin inline asm
	cvt.rn.bf16.f32 %rs254, %r1610;
	// end inline asm
	mov.b32 	%r1611, %f127;
	// begin inline asm
	cvt.rn.bf16.f32 %rs255, %r1611;
	// end inline asm
	mov.b32 	%r1612, %f128;
	// begin inline asm
	cvt.rn.bf16.f32 %rs256, %r1612;
	// end inline asm
	mov.b32 	%r1613, %f129;
	// begin inline asm
	cvt.rn.bf16.f32 %rs257, %r1613;
	// end inline asm
	mov.b32 	%r1614, %f130;
	// begin inline asm
	cvt.rn.bf16.f32 %rs258, %r1614;
	// end inline asm
	mov.b32 	%r1615, %f131;
	// begin inline asm
	cvt.rn.bf16.f32 %rs259, %r1615;
	// end inline asm
	mov.b32 	%r1616, %f132;
	// begin inline asm
	cvt.rn.bf16.f32 %rs260, %r1616;
	// end inline asm
	mov.b32 	%r1617, %f133;
	// begin inline asm
	cvt.rn.bf16.f32 %rs261, %r1617;
	// end inline asm
	mov.b32 	%r1618, %f134;
	// begin inline asm
	cvt.rn.bf16.f32 %rs262, %r1618;
	// end inline asm
	mov.b32 	%r1619, %f135;
	// begin inline asm
	cvt.rn.bf16.f32 %rs263, %r1619;
	// end inline asm
	mov.b32 	%r1620, %f136;
	// begin inline asm
	cvt.rn.bf16.f32 %rs264, %r1620;
	// end inline asm
	mov.b32 	%r1621, %f137;
	// begin inline asm
	cvt.rn.bf16.f32 %rs265, %r1621;
	// end inline asm
	mov.b32 	%r1622, %f138;
	// begin inline asm
	cvt.rn.bf16.f32 %rs266, %r1622;
	// end inline asm
	mov.b32 	%r1623, %f139;
	// begin inline asm
	cvt.rn.bf16.f32 %rs267, %r1623;
	// end inline asm
	mov.b32 	%r1624, %f140;
	// begin inline asm
	cvt.rn.bf16.f32 %rs268, %r1624;
	// end inline asm
	mov.b32 	%r1625, %f141;
	// begin inline asm
	cvt.rn.bf16.f32 %rs269, %r1625;
	// end inline asm
	mov.b32 	%r1626, %f142;
	// begin inline asm
	cvt.rn.bf16.f32 %rs270, %r1626;
	// end inline asm
	mov.b32 	%r1627, %f143;
	// begin inline asm
	cvt.rn.bf16.f32 %rs271, %r1627;
	// end inline asm
	mov.b32 	%r1628, %f144;
	// begin inline asm
	cvt.rn.bf16.f32 %rs272, %r1628;
	// end inline asm
	mov.b32 	%r1629, %f145;
	// begin inline asm
	cvt.rn.bf16.f32 %rs273, %r1629;
	// end inline asm
	mov.b32 	%r1630, %f146;
	// begin inline asm
	cvt.rn.bf16.f32 %rs274, %r1630;
	// end inline asm
	mov.b32 	%r1631, %f147;
	// begin inline asm
	cvt.rn.bf16.f32 %rs275, %r1631;
	// end inline asm
	mov.b32 	%r1632, %f148;
	// begin inline asm
	cvt.rn.bf16.f32 %rs276, %r1632;
	// end inline asm
	mov.b32 	%r1633, %f149;
	// begin inline asm
	cvt.rn.bf16.f32 %rs277, %r1633;
	// end inline asm
	mov.b32 	%r1634, %f150;
	// begin inline asm
	cvt.rn.bf16.f32 %rs278, %r1634;
	// end inline asm
	mov.b32 	%r1635, %f151;
	// begin inline asm
	cvt.rn.bf16.f32 %rs279, %r1635;
	// end inline asm
	mov.b32 	%r1636, %f152;
	// begin inline asm
	cvt.rn.bf16.f32 %rs280, %r1636;
	// end inline asm
	mov.b32 	%r1637, %f153;
	// begin inline asm
	cvt.rn.bf16.f32 %rs281, %r1637;
	// end inline asm
	mov.b32 	%r1638, %f154;
	// begin inline asm
	cvt.rn.bf16.f32 %rs282, %r1638;
	// end inline asm
	mov.b32 	%r1639, %f155;
	// begin inline asm
	cvt.rn.bf16.f32 %rs283, %r1639;
	// end inline asm
	mov.b32 	%r1640, %f156;
	// begin inline asm
	cvt.rn.bf16.f32 %rs284, %r1640;
	// end inline asm
	mov.b32 	%r1641, %f157;
	// begin inline asm
	cvt.rn.bf16.f32 %rs285, %r1641;
	// end inline asm
	mov.b32 	%r1642, %f158;
	// begin inline asm
	cvt.rn.bf16.f32 %rs286, %r1642;
	// end inline asm
	mov.b32 	%r1643, %f159;
	// begin inline asm
	cvt.rn.bf16.f32 %rs287, %r1643;
	// end inline asm
	mov.b32 	%r1644, %f160;
	// begin inline asm
	cvt.rn.bf16.f32 %rs288, %r1644;
	// end inline asm
	mov.b32 	%r1645, %f161;
	// begin inline asm
	cvt.rn.bf16.f32 %rs289, %r1645;
	// end inline asm
	mov.b32 	%r1646, %f162;
	// begin inline asm
	cvt.rn.bf16.f32 %rs290, %r1646;
	// end inline asm
	mov.b32 	%r1647, %f163;
	// begin inline asm
	cvt.rn.bf16.f32 %rs291, %r1647;
	// end inline asm
	mov.b32 	%r1648, %f164;
	// begin inline asm
	cvt.rn.bf16.f32 %rs292, %r1648;
	// end inline asm
	mov.b32 	%r1649, %f165;
	// begin inline asm
	cvt.rn.bf16.f32 %rs293, %r1649;
	// end inline asm
	mov.b32 	%r1650, %f166;
	// begin inline asm
	cvt.rn.bf16.f32 %rs294, %r1650;
	// end inline asm
	mov.b32 	%r1651, %f167;
	// begin inline asm
	cvt.rn.bf16.f32 %rs295, %r1651;
	// end inline asm
	mov.b32 	%r1652, %f168;
	// begin inline asm
	cvt.rn.bf16.f32 %rs296, %r1652;
	// end inline asm
	mov.b32 	%r1653, %f169;
	// begin inline asm
	cvt.rn.bf16.f32 %rs297, %r1653;
	// end inline asm
	mov.b32 	%r1654, %f170;
	// begin inline asm
	cvt.rn.bf16.f32 %rs298, %r1654;
	// end inline asm
	mov.b32 	%r1655, %f171;
	// begin inline asm
	cvt.rn.bf16.f32 %rs299, %r1655;
	// end inline asm
	mov.b32 	%r1656, %f172;
	// begin inline asm
	cvt.rn.bf16.f32 %rs300, %r1656;
	// end inline asm
	mov.b32 	%r1657, %f173;
	// begin inline asm
	cvt.rn.bf16.f32 %rs301, %r1657;
	// end inline asm
	mov.b32 	%r1658, %f174;
	// begin inline asm
	cvt.rn.bf16.f32 %rs302, %r1658;
	// end inline asm
	mov.b32 	%r1659, %f175;
	// begin inline asm
	cvt.rn.bf16.f32 %rs303, %r1659;
	// end inline asm
	mov.b32 	%r1660, %f176;
	// begin inline asm
	cvt.rn.bf16.f32 %rs304, %r1660;
	// end inline asm
	mov.b32 	%r1661, %f177;
	// begin inline asm
	cvt.rn.bf16.f32 %rs305, %r1661;
	// end inline asm
	mov.b32 	%r1662, %f178;
	// begin inline asm
	cvt.rn.bf16.f32 %rs306, %r1662;
	// end inline asm
	mov.b32 	%r1663, %f179;
	// begin inline asm
	cvt.rn.bf16.f32 %rs307, %r1663;
	// end inline asm
	mov.b32 	%r1664, %f180;
	// begin inline asm
	cvt.rn.bf16.f32 %rs308, %r1664;
	// end inline asm
	mov.b32 	%r1665, %f181;
	// begin inline asm
	cvt.rn.bf16.f32 %rs309, %r1665;
	// end inline asm
	mov.b32 	%r1666, %f182;
	// begin inline asm
	cvt.rn.bf16.f32 %rs310, %r1666;
	// end inline asm
	mov.b32 	%r1667, %f183;
	// begin inline asm
	cvt.rn.bf16.f32 %rs311, %r1667;
	// end inline asm
	mov.b32 	%r1668, %f184;
	// begin inline asm
	cvt.rn.bf16.f32 %rs312, %r1668;
	// end inline asm
	mov.b32 	%r1669, %f185;
	// begin inline asm
	cvt.rn.bf16.f32 %rs313, %r1669;
	// end inline asm
	mov.b32 	%r1670, %f186;
	// begin inline asm
	cvt.rn.bf16.f32 %rs314, %r1670;
	// end inline asm
	mov.b32 	%r1671, %f187;
	// begin inline asm
	cvt.rn.bf16.f32 %rs315, %r1671;
	// end inline asm
	mov.b32 	%r1672, %f188;
	// begin inline asm
	cvt.rn.bf16.f32 %rs316, %r1672;
	// end inline asm
	mov.b32 	%r1673, %f189;
	// begin inline asm
	cvt.rn.bf16.f32 %rs317, %r1673;
	// end inline asm
	mov.b32 	%r1674, %f190;
	// begin inline asm
	cvt.rn.bf16.f32 %rs318, %r1674;
	// end inline asm
	mov.b32 	%r1675, %f191;
	// begin inline asm
	cvt.rn.bf16.f32 %rs319, %r1675;
	// end inline asm
	mov.b32 	%r1676, %f192;
	// begin inline asm
	cvt.rn.bf16.f32 %rs320, %r1676;
	// end inline asm
	.loc	1 196 21
	mov.b32 	%r1856, {%rs193, %rs194};
	mov.b32 	%r1857, {%rs195, %rs196};
	mov.b32 	%r1858, {%rs197, %rs198};
	mov.b32 	%r1859, {%rs199, %rs200};
	// begin inline asm
	@%p60 st.global.v4.b32 [ %rd83 + 0 ], { %r1856, %r1857, %r1858, %r1859 };
	// end inline asm
	mov.b32 	%r1860, {%rs201, %rs202};
	mov.b32 	%r1861, {%rs203, %rs204};
	mov.b32 	%r1862, {%rs205, %rs206};
	mov.b32 	%r1863, {%rs207, %rs208};
	// begin inline asm
	@%p61 st.global.v4.b32 [ %rd84 + 0 ], { %r1860, %r1861, %r1862, %r1863 };
	// end inline asm
	mov.b32 	%r1864, {%rs209, %rs210};
	mov.b32 	%r1865, {%rs211, %rs212};
	mov.b32 	%r1866, {%rs213, %rs214};
	mov.b32 	%r1867, {%rs215, %rs216};
	// begin inline asm
	@%p62 st.global.v4.b32 [ %rd85 + 0 ], { %r1864, %r1865, %r1866, %r1867 };
	// end inline asm
	mov.b32 	%r1868, {%rs217, %rs218};
	mov.b32 	%r1869, {%rs219, %rs220};
	mov.b32 	%r1870, {%rs221, %rs222};
	mov.b32 	%r1871, {%rs223, %rs224};
	// begin inline asm
	@%p63 st.global.v4.b32 [ %rd86 + 0 ], { %r1868, %r1869, %r1870, %r1871 };
	// end inline asm
	mov.b32 	%r1872, {%rs225, %rs226};
	mov.b32 	%r1873, {%rs227, %rs228};
	mov.b32 	%r1874, {%rs229, %rs230};
	mov.b32 	%r1875, {%rs231, %rs232};
	// begin inline asm
	@%p64 st.global.v4.b32 [ %rd87 + 0 ], { %r1872, %r1873, %r1874, %r1875 };
	// end inline asm
	mov.b32 	%r1876, {%rs233, %rs234};
	mov.b32 	%r1877, {%rs235, %rs236};
	mov.b32 	%r1878, {%rs237, %rs238};
	mov.b32 	%r1879, {%rs239, %rs240};
	// begin inline asm
	@%p65 st.global.v4.b32 [ %rd88 + 0 ], { %r1876, %r1877, %r1878, %r1879 };
	// end inline asm
	mov.b32 	%r1880, {%rs241, %rs242};
	mov.b32 	%r1881, {%rs243, %rs244};
	mov.b32 	%r1882, {%rs245, %rs246};
	mov.b32 	%r1883, {%rs247, %rs248};
	// begin inline asm
	@%p66 st.global.v4.b32 [ %rd89 + 0 ], { %r1880, %r1881, %r1882, %r1883 };
	// end inline asm
	mov.b32 	%r1884, {%rs249, %rs250};
	mov.b32 	%r1885, {%rs251, %rs252};
	mov.b32 	%r1886, {%rs253, %rs254};
	mov.b32 	%r1887, {%rs255, %rs256};
	// begin inline asm
	@%p67 st.global.v4.b32 [ %rd90 + 0 ], { %r1884, %r1885, %r1886, %r1887 };
	// end inline asm
	mov.b32 	%r1888, {%rs257, %rs258};
	mov.b32 	%r1889, {%rs259, %rs260};
	mov.b32 	%r1890, {%rs261, %rs262};
	mov.b32 	%r1891, {%rs263, %rs264};
	// begin inline asm
	@%p68 st.global.v4.b32 [ %rd91 + 0 ], { %r1888, %r1889, %r1890, %r1891 };
	// end inline asm
	mov.b32 	%r1892, {%rs265, %rs266};
	mov.b32 	%r1893, {%rs267, %rs268};
	mov.b32 	%r1894, {%rs269, %rs270};
	mov.b32 	%r1895, {%rs271, %rs272};
	// begin inline asm
	@%p69 st.global.v4.b32 [ %rd92 + 0 ], { %r1892, %r1893, %r1894, %r1895 };
	// end inline asm
	mov.b32 	%r1896, {%rs273, %rs274};
	mov.b32 	%r1897, {%rs275, %rs276};
	mov.b32 	%r1898, {%rs277, %rs278};
	mov.b32 	%r1899, {%rs279, %rs280};
	// begin inline asm
	@%p70 st.global.v4.b32 [ %rd93 + 0 ], { %r1896, %r1897, %r1898, %r1899 };
	// end inline asm
	mov.b32 	%r1900, {%rs281, %rs282};
	mov.b32 	%r1901, {%rs283, %rs284};
	mov.b32 	%r1902, {%rs285, %rs286};
	mov.b32 	%r1903, {%rs287, %rs288};
	// begin inline asm
	@%p71 st.global.v4.b32 [ %rd94 + 0 ], { %r1900, %r1901, %r1902, %r1903 };
	// end inline asm
	mov.b32 	%r1904, {%rs289, %rs290};
	mov.b32 	%r1905, {%rs291, %rs292};
	mov.b32 	%r1906, {%rs293, %rs294};
	mov.b32 	%r1907, {%rs295, %rs296};
	// begin inline asm
	@%p72 st.global.v4.b32 [ %rd95 + 0 ], { %r1904, %r1905, %r1906, %r1907 };
	// end inline asm
	mov.b32 	%r1908, {%rs297, %rs298};
	mov.b32 	%r1909, {%rs299, %rs300};
	mov.b32 	%r1910, {%rs301, %rs302};
	mov.b32 	%r1911, {%rs303, %rs304};
	// begin inline asm
	@%p73 st.global.v4.b32 [ %rd96 + 0 ], { %r1908, %r1909, %r1910, %r1911 };
	// end inline asm
	mov.b32 	%r1912, {%rs305, %rs306};
	mov.b32 	%r1913, {%rs307, %rs308};
	mov.b32 	%r1914, {%rs309, %rs310};
	mov.b32 	%r1915, {%rs311, %rs312};
	// begin inline asm
	@%p74 st.global.v4.b32 [ %rd97 + 0 ], { %r1912, %r1913, %r1914, %r1915 };
	// end inline asm
	mov.b32 	%r1916, {%rs313, %rs314};
	mov.b32 	%r1917, {%rs315, %rs316};
	mov.b32 	%r1918, {%rs317, %rs318};
	mov.b32 	%r1919, {%rs319, %rs320};
	// begin inline asm
	@%p75 st.global.v4.b32 [ %rd98 + 0 ], { %r1916, %r1917, %r1918, %r1919 };
	// end inline asm
	.loc	1 196 4
	ret;
$L__tmp6:
$L__func_end0:

}
	.file	1 "/home/mike/PycharmProjects/tritontest/compile_matmul_kernel.py"
	.file	2 "/home/mike/PycharmProjects/tritontest/.venv/lib/python3.11/site-packages/triton/language/standard.py"
	.section	.debug_abbrev
	{
.b8 1
.b8 17
.b8 1
.b8 37
.b8 8
.b8 19
.b8 5
.b8 3
.b8 8
.b8 16
.b8 6
.b8 27
.b8 8
.b8 17
.b8 1
.b8 18
.b8 1
.b8 0
.b8 0
.b8 2
.b8 46
.b8 0
.b8 3
.b8 8
.b8 32
.b8 11
.b8 0
.b8 0
.b8 3
.b8 46
.b8 1
.b8 17
.b8 1
.b8 18
.b8 1
.b8 49
.b8 19
.b8 0
.b8 0
.b8 4
.b8 29
.b8 0
.b8 49
.b8 19
.b8 17
.b8 1
.b8 18
.b8 1
.b8 88
.b8 11
.b8 89
.b8 11
.b8 87
.b8 11
.b8 0
.b8 0
.b8 0
	}
	.section	.debug_info
	{
.b32 211
.b8 2
.b8 0
.b32 .debug_abbrev
.b8 8
.b8 1
.b8 116
.b8 114
.b8 105
.b8 116
.b8 111
.b8 110
.b8 0
.b8 2
.b8 0
.b8 99
.b8 111
.b8 109
.b8 112
.b8 105
.b8 108
.b8 101
.b8 95
.b8 109
.b8 97
.b8 116
.b8 109
.b8 117
.b8 108
.b8 95
.b8 107
.b8 101
.b8 114
.b8 110
.b8 101
.b8 108
.b8 46
.b8 112
.b8 121
.b8 0
.b32 .debug_line
.b8 47
.b8 104
.b8 111
.b8 109
.b8 101
.b8 47
.b8 109
.b8 105
.b8 107
.b8 101
.b8 47
.b8 80
.b8 121
.b8 99
.b8 104
.b8 97
.b8 114
.b8 109
.b8 80
.b8 114
.b8 111
.b8 106
.b8 101
.b8 99
.b8 116
.b8 115
.b8 47
.b8 116
.b8 114
.b8 105
.b8 116
.b8 111
.b8 110
.b8 116
.b8 101
.b8 115
.b8 116
.b8 0
.b64 $L__func_begin0
.b64 $L__func_end0
.b8 2
.b8 109
.b8 97
.b8 116
.b8 109
.b8 117
.b8 108
.b8 95
.b8 107
.b8 101
.b8 114
.b8 110
.b8 101
.b8 108
.b8 0
.b8 1
.b8 3
.b64 $L__func_begin0
.b64 $L__func_end0
.b32 104
.b8 4
.b32 104
.b64 $L__tmp1
.b64 $L__tmp2
.b8 1
.b8 138
.b8 27
.b8 4
.b32 104
.b64 $L__tmp2
.b64 $L__tmp3
.b8 1
.b8 139
.b8 27
.b8 4
.b32 104
.b64 $L__tmp4
.b64 $L__tmp5
.b8 1
.b8 173
.b8 33
.b8 0
.b8 0
	}
	.section	.debug_loc	{	}